{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "class reader(object):\n",
    "  def __init__(self, data_file = \"./data/wdbc.data\"):\n",
    "    self.value = []\n",
    "    with open(data_file, \"rb\") as f:\n",
    "      csv_reader = csv.reader(f, delimiter=\",\")\n",
    "      for i, row in enumerate(csv_reader):\n",
    "        self.value.append(row)\n",
    "    # print self.value[0]\n",
    "    # print self.value[0][0]\n",
    "    # print self.value[0][1]\n",
    "\n",
    "    self.raw_to_vector(self.value)\n",
    "    self.split(num_validation_examples=114)\n",
    "    \n",
    "#     print self.id.shape\n",
    "    print self.x.shape\n",
    "    print self.y.shape\n",
    "    \n",
    "    self.num_examples = len(self.x_train)\n",
    "    self.start_index = 0\n",
    "    self.shuffle_indices = range(self.num_examples)\n",
    "\n",
    "    self.num_examples_val = len(self.x_val) # = 114 (validation_data)\n",
    "    self.start_index_val = 0\n",
    "    self.shuffle_indices_val = range(self.num_examples_val)\n",
    "    print self.num_examples_val\n",
    "\n",
    "  def raw_to_vector(self, value):\n",
    "    self.id = []\n",
    "    self.x = []\n",
    "    self.y = []\n",
    "\n",
    "    for row in self.value:\n",
    "        x = np.zeros(30)\n",
    "        for i in range(30):\n",
    "            x[i] = float(row[i+2])\n",
    "        if row[1] == \"B\":\n",
    "            y = 0\n",
    "        else:\n",
    "            y = 1\n",
    "        self.x.append(x)\n",
    "        self.y.append(y)\n",
    "        id = int(row[0])\n",
    "        self.id.append(id)\n",
    "        \n",
    "    self.x, self.y, self.id = np.array(self.x), np.array(self.y), np.array(self.id)\n",
    "\n",
    "  def split(self, num_validation_examples):\n",
    "    self.x_train = self.x[ num_validation_examples: ]\n",
    "    self.x_val = self.x[ : num_validation_examples ]\n",
    "\n",
    "    self.y_train = self.y[ num_validation_examples: ]\n",
    "    self.y_val = self.y[ : num_validation_examples ]\n",
    "\n",
    "    self.id_train = self.id[ num_validation_examples: ]\n",
    "    self.id_val = self.id[ :num_validation_examples ]\n",
    "\n",
    "  def next_batch(self, batch_size, split=\"train\"):\n",
    "\n",
    "    if split == \"train\":\n",
    "      if self.start_index == 0:\n",
    "        np.random.shuffle(self.shuffle_indices) # shuffle indices\n",
    "\n",
    "      end_index = min([self.num_examples, self.start_index + batch_size])\n",
    "      batch_indices = [ self.shuffle_indices[idx] for idx in range(self.start_index, end_index) ]\n",
    "\n",
    "      batch_x = self.x_train[ batch_indices ]\n",
    "      batch_y = self.y_train[ batch_indices ]\n",
    "      batch_id = self.id_train[ batch_indices ] \n",
    "\n",
    "      if end_index == self.num_examples:\n",
    "        self.start_index = 0\n",
    "      else: self.start_index = end_index\n",
    "\n",
    "      return batch_x, batch_y, batch_id \n",
    "\n",
    "    elif split == \"val\":\n",
    "      if self.start_index_val == 0:\n",
    "        np.random.shuffle(self.shuffle_indices_val) # shuffle indices\n",
    "\n",
    "      end_index = min([self.num_examples_val, self.start_index_val + batch_size])\n",
    "      batch_indices = [ self.shuffle_indices_val[idx] for idx in range(self.start_index_val, end_index) ]\n",
    "\n",
    "      batch_x = self.x_val[ batch_indices ]\n",
    "      batch_y = self.y_val[ batch_indices ]\n",
    "      batch_id = self.id_val[ batch_indices ] \n",
    "\n",
    "      if end_index == self.num_examples_val:\n",
    "        self.start_index_val = 0\n",
    "      else: self.start_index_val = end_index\n",
    "\n",
    "      return batch_x, batch_y, batch_id  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class dnn(object):\n",
    "  def __init__(self):\n",
    "    # Define model's input as tf.placeholder\n",
    "    self.x = tf.placeholder(dtype=tf.float32, shape=[None, 30])\n",
    "    self.y = tf.placeholder(dtype=tf.int32, shape=[None])\n",
    "\n",
    "    \n",
    "    # Define parameters for 3-layers dnn model\n",
    "    self.w_1, self.b_1 = tf.get_variable(name=\"w_1\", shape=[30, 128]), tf.get_variable(name=\"b_1\", shape=[128])\n",
    "    self.w_2, self.b_2 = tf.get_variable(name=\"w_2\", shape=[128, 128]), tf.get_variable(name=\"b_2\", shape=[128])\n",
    "    self.w_3, self.b_3 = tf.get_variable(name=\"w_3\", shape=[128, 2]), tf.get_variable(name=\"b_3\", shape=[2])\n",
    "\n",
    "\n",
    "    # build graph for forward & backward propagation\n",
    "    self.build_graph()\n",
    "\n",
    "\n",
    "  def build_graph(self):\n",
    "\n",
    "    # h1.shape = (batch, 50)\n",
    "    h1 = tf.matmul(self.x, self.w_1) + self.b_1 \n",
    "    h1 = tf.nn.relu(h1)\n",
    "\n",
    "    # h2.shape = (batch, 50)\n",
    "    h2 = tf.matmul(h1, self.w_2) + self.b_2\n",
    "    h2 = tf.nn.relu(h2)\n",
    "\n",
    "    # h3.shape = (batch, 2)\n",
    "    h3 = tf.matmul(h2, self.w_3) + self.b_3\n",
    "    h3 = tf.nn.softmax(h3, dim=-1)\n",
    "\n",
    "    prediction = h3\n",
    "\n",
    "    y_onehot = tf.one_hot(\n",
    "      indices=self.y,\n",
    "      depth=2,\n",
    "      on_value=1.0,\n",
    "      off_value=0.0,\n",
    "      )\n",
    "\n",
    "    # We use L2 loss as cost function and average the batch's loss\n",
    "    self.loss = tf.reduce_mean((y_onehot - prediction) * (y_onehot - prediction))\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    \n",
    "    self.train_op = optimizer.minimize(self.loss)\n",
    "\n",
    "    pred_index = tf.cast(tf.argmax(prediction, dimension=1), tf.int32)\n",
    "    correct_prediction = tf.equal(pred_index, self.y)\n",
    "    self.acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(569,)\n",
      "114\n",
      "| steps 0000000 | loss: 0.312\n",
      "| steps 0000000 | Validation Accuracy: 0.404\n",
      "| steps 0000100 | loss: 0.250\n",
      "| steps 0000100 | Validation Accuracy: 0.404\n",
      "| steps 0000200 | loss: 0.344\n",
      "| steps 0000200 | Validation Accuracy: 0.439\n",
      "| steps 0000300 | loss: 0.312\n",
      "| steps 0000300 | Validation Accuracy: 0.368\n",
      "| steps 0000400 | loss: 0.312\n",
      "| steps 0000400 | Validation Accuracy: 0.404\n",
      "| steps 0000500 | loss: 0.406\n",
      "| steps 0000500 | Validation Accuracy: 0.404\n",
      "| steps 0000600 | loss: 0.188\n",
      "| steps 0000600 | Validation Accuracy: 0.526\n",
      "| steps 0000700 | loss: 0.406\n",
      "| steps 0000700 | Validation Accuracy: 0.281\n",
      "| steps 0000800 | loss: 0.219\n",
      "| steps 0000800 | Validation Accuracy: 0.456\n",
      "| steps 0000900 | loss: 0.406\n",
      "| steps 0000900 | Validation Accuracy: 0.351\n",
      "| steps 0001000 | loss: 0.344\n",
      "| steps 0001000 | Validation Accuracy: 0.404\n",
      "| steps 0001100 | loss: 0.344\n",
      "| steps 0001100 | Validation Accuracy: 0.404\n",
      "| steps 0001200 | loss: 0.312\n",
      "| steps 0001200 | Validation Accuracy: 0.404\n",
      "| steps 0001300 | loss: 0.312\n",
      "| steps 0001300 | Validation Accuracy: 0.404\n",
      "| steps 0001400 | loss: 0.375\n",
      "| steps 0001400 | Validation Accuracy: 0.404\n",
      "| steps 0001500 | loss: 0.344\n",
      "| steps 0001500 | Validation Accuracy: 0.404\n",
      "| steps 0001600 | loss: 0.406\n",
      "| steps 0001600 | Validation Accuracy: 0.351\n",
      "| steps 0001700 | loss: 0.344\n",
      "| steps 0001700 | Validation Accuracy: 0.456\n",
      "| steps 0001800 | loss: 0.344\n",
      "| steps 0001800 | Validation Accuracy: 0.474\n",
      "| steps 0001900 | loss: 0.156\n",
      "| steps 0001900 | Validation Accuracy: 0.333\n",
      "| steps 0002000 | loss: 0.250\n",
      "| steps 0002000 | Validation Accuracy: 0.351\n",
      "| steps 0002100 | loss: 0.250\n",
      "| steps 0002100 | Validation Accuracy: 0.456\n",
      "| steps 0002200 | loss: 0.375\n",
      "| steps 0002200 | Validation Accuracy: 0.439\n",
      "| steps 0002300 | loss: 0.250\n",
      "| steps 0002300 | Validation Accuracy: 0.368\n",
      "| steps 0002400 | loss: 0.375\n",
      "| steps 0002400 | Validation Accuracy: 0.474\n",
      "| steps 0002500 | loss: 0.375\n",
      "| steps 0002500 | Validation Accuracy: 0.333\n",
      "| steps 0002600 | loss: 0.344\n",
      "| steps 0002600 | Validation Accuracy: 0.404\n",
      "| steps 0002700 | loss: 0.375\n",
      "| steps 0002700 | Validation Accuracy: 0.404\n",
      "| steps 0002800 | loss: 0.281\n",
      "| steps 0002800 | Validation Accuracy: 0.298\n",
      "| steps 0002900 | loss: 0.406\n",
      "| steps 0002900 | Validation Accuracy: 0.509\n",
      "| steps 0003000 | loss: 0.344\n",
      "| steps 0003000 | Validation Accuracy: 0.351\n",
      "| steps 0003100 | loss: 0.344\n",
      "| steps 0003100 | Validation Accuracy: 0.456\n",
      "| steps 0003200 | loss: 0.281\n",
      "| steps 0003200 | Validation Accuracy: 0.404\n",
      "| steps 0003300 | loss: 0.281\n",
      "| steps 0003300 | Validation Accuracy: 0.404\n",
      "| steps 0003400 | loss: 0.219\n",
      "| steps 0003400 | Validation Accuracy: 0.491\n",
      "| steps 0003500 | loss: 0.375\n",
      "| steps 0003500 | Validation Accuracy: 0.316\n",
      "| steps 0003600 | loss: 0.188\n",
      "| steps 0003600 | Validation Accuracy: 0.333\n",
      "| steps 0003700 | loss: 0.344\n",
      "| steps 0003700 | Validation Accuracy: 0.474\n",
      "| steps 0003800 | loss: 0.344\n",
      "| steps 0003800 | Validation Accuracy: 0.456\n",
      "| steps 0003900 | loss: 0.312\n",
      "| steps 0003900 | Validation Accuracy: 0.351\n",
      "| steps 0004000 | loss: 0.312\n",
      "| steps 0004000 | Validation Accuracy: 0.404\n",
      "| steps 0004100 | loss: 0.219\n",
      "| steps 0004100 | Validation Accuracy: 0.404\n",
      "| steps 0004200 | loss: 0.375\n",
      "| steps 0004200 | Validation Accuracy: 0.351\n",
      "| steps 0004300 | loss: 0.281\n",
      "| steps 0004300 | Validation Accuracy: 0.456\n",
      "| steps 0004400 | loss: 0.312\n",
      "| steps 0004400 | Validation Accuracy: 0.351\n",
      "| steps 0004500 | loss: 0.312\n",
      "| steps 0004500 | Validation Accuracy: 0.456\n",
      "| steps 0004600 | loss: 0.344\n",
      "| steps 0004600 | Validation Accuracy: 0.368\n",
      "| steps 0004700 | loss: 0.312\n",
      "| steps 0004700 | Validation Accuracy: 0.439\n",
      "| steps 0004800 | loss: 0.312\n",
      "| steps 0004800 | Validation Accuracy: 0.439\n",
      "| steps 0004900 | loss: 0.188\n",
      "| steps 0004900 | Validation Accuracy: 0.368\n",
      "| steps 0005000 | loss: 0.344\n",
      "| steps 0005000 | Validation Accuracy: 0.439\n",
      "| steps 0005100 | loss: 0.188\n",
      "| steps 0005100 | Validation Accuracy: 0.368\n",
      "| steps 0005200 | loss: 0.469\n",
      "| steps 0005200 | Validation Accuracy: 0.368\n",
      "| steps 0005300 | loss: 0.281\n",
      "| steps 0005300 | Validation Accuracy: 0.439\n",
      "| steps 0005400 | loss: 0.156\n",
      "| steps 0005400 | Validation Accuracy: 0.421\n",
      "| steps 0005500 | loss: 0.219\n",
      "| steps 0005500 | Validation Accuracy: 0.386\n",
      "| steps 0005600 | loss: 0.219\n",
      "| steps 0005600 | Validation Accuracy: 0.421\n",
      "| steps 0005700 | loss: 0.344\n",
      "| steps 0005700 | Validation Accuracy: 0.386\n",
      "| steps 0005800 | loss: 0.438\n",
      "| steps 0005800 | Validation Accuracy: 0.421\n",
      "| steps 0005900 | loss: 0.438\n",
      "| steps 0005900 | Validation Accuracy: 0.386\n",
      "| steps 0006000 | loss: 0.281\n",
      "| steps 0006000 | Validation Accuracy: 0.421\n",
      "| steps 0006100 | loss: 0.375\n",
      "| steps 0006100 | Validation Accuracy: 0.386\n",
      "| steps 0006200 | loss: 0.188\n",
      "| steps 0006200 | Validation Accuracy: 0.474\n",
      "| steps 0006300 | loss: 0.250\n",
      "| steps 0006300 | Validation Accuracy: 0.333\n",
      "| steps 0006400 | loss: 0.344\n",
      "| steps 0006400 | Validation Accuracy: 0.439\n",
      "| steps 0006500 | loss: 0.281\n",
      "| steps 0006500 | Validation Accuracy: 0.368\n",
      "| steps 0006600 | loss: 0.406\n",
      "| steps 0006600 | Validation Accuracy: 0.351\n",
      "| steps 0006700 | loss: 0.375\n",
      "| steps 0006700 | Validation Accuracy: 0.456\n",
      "| steps 0006800 | loss: 0.438\n",
      "| steps 0006800 | Validation Accuracy: 0.368\n",
      "| steps 0006900 | loss: 0.438\n",
      "| steps 0006900 | Validation Accuracy: 0.439\n",
      "| steps 0007000 | loss: 0.250\n",
      "| steps 0007000 | Validation Accuracy: 0.544\n",
      "| steps 0007100 | loss: 0.344\n",
      "| steps 0007100 | Validation Accuracy: 0.263\n",
      "| steps 0007200 | loss: 0.250\n",
      "| steps 0007200 | Validation Accuracy: 0.421\n",
      "| steps 0007300 | loss: 0.250\n",
      "| steps 0007300 | Validation Accuracy: 0.386\n",
      "| steps 0007400 | loss: 0.438\n",
      "| steps 0007400 | Validation Accuracy: 0.351\n",
      "| steps 0007500 | loss: 0.344\n",
      "| steps 0007500 | Validation Accuracy: 0.456\n",
      "| steps 0007600 | loss: 0.250\n",
      "| steps 0007600 | Validation Accuracy: 0.404\n",
      "| steps 0007700 | loss: 0.406\n",
      "| steps 0007700 | Validation Accuracy: 0.404\n",
      "| steps 0007800 | loss: 0.219\n",
      "| steps 0007800 | Validation Accuracy: 0.333\n",
      "| steps 0007900 | loss: 0.438\n",
      "| steps 0007900 | Validation Accuracy: 0.474\n",
      "| steps 0008000 | loss: 0.219\n",
      "| steps 0008000 | Validation Accuracy: 0.333\n",
      "| steps 0008100 | loss: 0.312\n",
      "| steps 0008100 | Validation Accuracy: 0.474\n",
      "| steps 0008200 | loss: 0.500\n",
      "| steps 0008200 | Validation Accuracy: 0.421\n",
      "| steps 0008300 | loss: 0.188\n",
      "| steps 0008300 | Validation Accuracy: 0.386\n",
      "| steps 0008400 | loss: 0.375\n",
      "| steps 0008400 | Validation Accuracy: 0.368\n",
      "| steps 0008500 | loss: 0.219\n",
      "| steps 0008500 | Validation Accuracy: 0.439\n",
      "| steps 0008600 | loss: 0.250\n",
      "| steps 0008600 | Validation Accuracy: 0.491\n",
      "| steps 0008700 | loss: 0.250\n",
      "| steps 0008700 | Validation Accuracy: 0.316\n",
      "| steps 0008800 | loss: 0.344\n",
      "| steps 0008800 | Validation Accuracy: 0.439\n",
      "| steps 0008900 | loss: 0.312\n",
      "| steps 0008900 | Validation Accuracy: 0.368\n",
      "| steps 0009000 | loss: 0.312\n",
      "| steps 0009000 | Validation Accuracy: 0.368\n",
      "| steps 0009100 | loss: 0.281\n",
      "| steps 0009100 | Validation Accuracy: 0.439\n",
      "| steps 0009200 | loss: 0.438\n",
      "| steps 0009200 | Validation Accuracy: 0.421\n",
      "| steps 0009300 | loss: 0.312\n",
      "| steps 0009300 | Validation Accuracy: 0.386\n",
      "| steps 0009400 | loss: 0.281\n",
      "| steps 0009400 | Validation Accuracy: 0.404\n",
      "| steps 0009500 | loss: 0.156\n",
      "| steps 0009500 | Validation Accuracy: 0.404\n",
      "| steps 0009600 | loss: 0.531\n",
      "| steps 0009600 | Validation Accuracy: 0.421\n",
      "| steps 0009700 | loss: 0.312\n",
      "| steps 0009700 | Validation Accuracy: 0.386\n",
      "| steps 0009800 | loss: 0.406\n",
      "| steps 0009800 | Validation Accuracy: 0.474\n",
      "| steps 0009900 | loss: 0.375\n",
      "| steps 0009900 | Validation Accuracy: 0.333\n",
      "| steps 0010000 | loss: 0.375\n",
      "| steps 0010000 | Validation Accuracy: 0.404\n",
      "| steps 0010100 | loss: 0.406\n",
      "| steps 0010100 | Validation Accuracy: 0.404\n",
      "| steps 0010200 | loss: 0.344\n",
      "| steps 0010200 | Validation Accuracy: 0.351\n",
      "| steps 0010300 | loss: 0.438\n",
      "| steps 0010300 | Validation Accuracy: 0.456\n",
      "| steps 0010400 | loss: 0.219\n",
      "| steps 0010400 | Validation Accuracy: 0.421\n",
      "| steps 0010500 | loss: 0.344\n",
      "| steps 0010500 | Validation Accuracy: 0.386\n",
      "| steps 0010600 | loss: 0.375\n",
      "| steps 0010600 | Validation Accuracy: 0.404\n",
      "| steps 0010700 | loss: 0.375\n",
      "| steps 0010700 | Validation Accuracy: 0.404\n",
      "| steps 0010800 | loss: 0.312\n",
      "| steps 0010800 | Validation Accuracy: 0.404\n",
      "| steps 0010900 | loss: 0.375\n",
      "| steps 0010900 | Validation Accuracy: 0.404\n",
      "| steps 0011000 | loss: 0.281\n",
      "| steps 0011000 | Validation Accuracy: 0.509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| steps 0011100 | loss: 0.375\n",
      "| steps 0011100 | Validation Accuracy: 0.298\n",
      "| steps 0011200 | loss: 0.281\n",
      "| steps 0011200 | Validation Accuracy: 0.421\n",
      "| steps 0011300 | loss: 0.312\n",
      "| steps 0011300 | Validation Accuracy: 0.386\n",
      "| steps 0011400 | loss: 0.406\n",
      "| steps 0011400 | Validation Accuracy: 0.421\n",
      "| steps 0011500 | loss: 0.219\n",
      "| steps 0011500 | Validation Accuracy: 0.386\n",
      "| steps 0011600 | loss: 0.344\n",
      "| steps 0011600 | Validation Accuracy: 0.439\n",
      "| steps 0011700 | loss: 0.375\n",
      "| steps 0011700 | Validation Accuracy: 0.368\n",
      "| steps 0011800 | loss: 0.281\n",
      "| steps 0011800 | Validation Accuracy: 0.474\n",
      "| steps 0011900 | loss: 0.281\n",
      "| steps 0011900 | Validation Accuracy: 0.333\n",
      "| steps 0012000 | loss: 0.281\n",
      "| steps 0012000 | Validation Accuracy: 0.421\n",
      "| steps 0012100 | loss: 0.250\n",
      "| steps 0012100 | Validation Accuracy: 0.386\n",
      "| steps 0012200 | loss: 0.406\n",
      "| steps 0012200 | Validation Accuracy: 0.439\n",
      "| steps 0012300 | loss: 0.469\n",
      "| steps 0012300 | Validation Accuracy: 0.368\n",
      "| steps 0012400 | loss: 0.406\n",
      "| steps 0012400 | Validation Accuracy: 0.421\n",
      "| steps 0012500 | loss: 0.281\n",
      "| steps 0012500 | Validation Accuracy: 0.386\n",
      "| steps 0012600 | loss: 0.250\n",
      "| steps 0012600 | Validation Accuracy: 0.351\n",
      "| steps 0012700 | loss: 0.344\n",
      "| steps 0012700 | Validation Accuracy: 0.456\n",
      "| steps 0012800 | loss: 0.406\n",
      "| steps 0012800 | Validation Accuracy: 0.404\n",
      "| steps 0012900 | loss: 0.219\n",
      "| steps 0012900 | Validation Accuracy: 0.404\n",
      "| steps 0013000 | loss: 0.312\n",
      "| steps 0013000 | Validation Accuracy: 0.386\n",
      "| steps 0013100 | loss: 0.312\n",
      "| steps 0013100 | Validation Accuracy: 0.421\n",
      "| steps 0013200 | loss: 0.344\n",
      "| steps 0013200 | Validation Accuracy: 0.404\n",
      "| steps 0013300 | loss: 0.312\n",
      "| steps 0013300 | Validation Accuracy: 0.404\n",
      "| steps 0013400 | loss: 0.281\n",
      "| steps 0013400 | Validation Accuracy: 0.368\n",
      "| steps 0013500 | loss: 0.312\n",
      "| steps 0013500 | Validation Accuracy: 0.439\n",
      "| steps 0013600 | loss: 0.344\n",
      "| steps 0013600 | Validation Accuracy: 0.439\n",
      "| steps 0013700 | loss: 0.219\n",
      "| steps 0013700 | Validation Accuracy: 0.368\n",
      "| steps 0013800 | loss: 0.312\n",
      "| steps 0013800 | Validation Accuracy: 0.404\n",
      "| steps 0013900 | loss: 0.312\n",
      "| steps 0013900 | Validation Accuracy: 0.404\n",
      "| steps 0014000 | loss: 0.312\n",
      "| steps 0014000 | Validation Accuracy: 0.368\n",
      "| steps 0014100 | loss: 0.281\n",
      "| steps 0014100 | Validation Accuracy: 0.439\n",
      "| steps 0014200 | loss: 0.312\n",
      "| steps 0014200 | Validation Accuracy: 0.439\n",
      "| steps 0014300 | loss: 0.344\n",
      "| steps 0014300 | Validation Accuracy: 0.368\n",
      "| steps 0014400 | loss: 0.344\n",
      "| steps 0014400 | Validation Accuracy: 0.368\n",
      "| steps 0014500 | loss: 0.250\n",
      "| steps 0014500 | Validation Accuracy: 0.439\n",
      "| steps 0014600 | loss: 0.250\n",
      "| steps 0014600 | Validation Accuracy: 0.386\n",
      "| steps 0014700 | loss: 0.219\n",
      "| steps 0014700 | Validation Accuracy: 0.421\n",
      "| steps 0014800 | loss: 0.344\n",
      "| steps 0014800 | Validation Accuracy: 0.421\n",
      "| steps 0014900 | loss: 0.344\n",
      "| steps 0014900 | Validation Accuracy: 0.386\n",
      "| steps 0015000 | loss: 0.344\n",
      "| steps 0015000 | Validation Accuracy: 0.333\n",
      "| steps 0015100 | loss: 0.438\n",
      "| steps 0015100 | Validation Accuracy: 0.474\n",
      "| steps 0015200 | loss: 0.156\n",
      "| steps 0015200 | Validation Accuracy: 0.456\n",
      "| steps 0015300 | loss: 0.344\n",
      "| steps 0015300 | Validation Accuracy: 0.351\n",
      "| steps 0015400 | loss: 0.344\n",
      "| steps 0015400 | Validation Accuracy: 0.333\n",
      "| steps 0015500 | loss: 0.469\n",
      "| steps 0015500 | Validation Accuracy: 0.474\n",
      "| steps 0015600 | loss: 0.344\n",
      "| steps 0015600 | Validation Accuracy: 0.421\n",
      "| steps 0015700 | loss: 0.250\n",
      "| steps 0015700 | Validation Accuracy: 0.386\n",
      "| steps 0015800 | loss: 0.188\n",
      "| steps 0015800 | Validation Accuracy: 0.386\n",
      "| steps 0015900 | loss: 0.219\n",
      "| steps 0015900 | Validation Accuracy: 0.421\n",
      "| steps 0016000 | loss: 0.312\n",
      "| steps 0016000 | Validation Accuracy: 0.421\n",
      "| steps 0016100 | loss: 0.344\n",
      "| steps 0016100 | Validation Accuracy: 0.386\n",
      "| steps 0016200 | loss: 0.250\n",
      "| steps 0016200 | Validation Accuracy: 0.386\n",
      "| steps 0016300 | loss: 0.281\n",
      "| steps 0016300 | Validation Accuracy: 0.421\n",
      "| steps 0016400 | loss: 0.312\n",
      "| steps 0016400 | Validation Accuracy: 0.368\n",
      "| steps 0016500 | loss: 0.219\n",
      "| steps 0016500 | Validation Accuracy: 0.439\n",
      "| steps 0016600 | loss: 0.375\n",
      "| steps 0016600 | Validation Accuracy: 0.456\n",
      "| steps 0016700 | loss: 0.250\n",
      "| steps 0016700 | Validation Accuracy: 0.351\n",
      "| steps 0016800 | loss: 0.312\n",
      "| steps 0016800 | Validation Accuracy: 0.298\n",
      "| steps 0016900 | loss: 0.219\n",
      "| steps 0016900 | Validation Accuracy: 0.509\n",
      "| steps 0017000 | loss: 0.406\n",
      "| steps 0017000 | Validation Accuracy: 0.439\n",
      "| steps 0017100 | loss: 0.250\n",
      "| steps 0017100 | Validation Accuracy: 0.368\n",
      "| steps 0017200 | loss: 0.250\n",
      "| steps 0017200 | Validation Accuracy: 0.456\n",
      "| steps 0017300 | loss: 0.312\n",
      "| steps 0017300 | Validation Accuracy: 0.351\n",
      "| steps 0017400 | loss: 0.344\n",
      "| steps 0017400 | Validation Accuracy: 0.421\n",
      "| steps 0017500 | loss: 0.312\n",
      "| steps 0017500 | Validation Accuracy: 0.386\n",
      "| steps 0017600 | loss: 0.344\n",
      "| steps 0017600 | Validation Accuracy: 0.474\n",
      "| steps 0017700 | loss: 0.438\n",
      "| steps 0017700 | Validation Accuracy: 0.333\n",
      "| steps 0017800 | loss: 0.188\n",
      "| steps 0017800 | Validation Accuracy: 0.368\n",
      "| steps 0017900 | loss: 0.438\n",
      "| steps 0017900 | Validation Accuracy: 0.439\n",
      "| steps 0018000 | loss: 0.406\n",
      "| steps 0018000 | Validation Accuracy: 0.386\n",
      "| steps 0018100 | loss: 0.188\n",
      "| steps 0018100 | Validation Accuracy: 0.421\n",
      "| steps 0018200 | loss: 0.312\n",
      "| steps 0018200 | Validation Accuracy: 0.386\n",
      "| steps 0018300 | loss: 0.281\n",
      "| steps 0018300 | Validation Accuracy: 0.421\n",
      "| steps 0018400 | loss: 0.281\n",
      "| steps 0018400 | Validation Accuracy: 0.474\n",
      "| steps 0018500 | loss: 0.375\n",
      "| steps 0018500 | Validation Accuracy: 0.333\n",
      "| steps 0018600 | loss: 0.281\n",
      "| steps 0018600 | Validation Accuracy: 0.474\n",
      "| steps 0018700 | loss: 0.469\n",
      "| steps 0018700 | Validation Accuracy: 0.333\n",
      "| steps 0018800 | loss: 0.281\n",
      "| steps 0018800 | Validation Accuracy: 0.333\n",
      "| steps 0018900 | loss: 0.312\n",
      "| steps 0018900 | Validation Accuracy: 0.474\n",
      "| steps 0019000 | loss: 0.438\n",
      "| steps 0019000 | Validation Accuracy: 0.368\n",
      "| steps 0019100 | loss: 0.281\n",
      "| steps 0019100 | Validation Accuracy: 0.439\n",
      "| steps 0019200 | loss: 0.375\n",
      "| steps 0019200 | Validation Accuracy: 0.439\n",
      "| steps 0019300 | loss: 0.375\n",
      "| steps 0019300 | Validation Accuracy: 0.368\n",
      "| steps 0019400 | loss: 0.281\n",
      "| steps 0019400 | Validation Accuracy: 0.439\n",
      "| steps 0019500 | loss: 0.406\n",
      "| steps 0019500 | Validation Accuracy: 0.368\n",
      "| steps 0019600 | loss: 0.375\n",
      "| steps 0019600 | Validation Accuracy: 0.333\n",
      "| steps 0019700 | loss: 0.281\n",
      "| steps 0019700 | Validation Accuracy: 0.474\n",
      "| steps 0019800 | loss: 0.312\n",
      "| steps 0019800 | Validation Accuracy: 0.404\n",
      "| steps 0019900 | loss: 0.375\n",
      "| steps 0019900 | Validation Accuracy: 0.404\n",
      "| steps 0020000 | loss: 0.312\n",
      "| steps 0020000 | Validation Accuracy: 0.456\n",
      "| steps 0020100 | loss: 0.406\n",
      "| steps 0020100 | Validation Accuracy: 0.351\n",
      "| steps 0020200 | loss: 0.500\n",
      "| steps 0020200 | Validation Accuracy: 0.456\n",
      "| steps 0020300 | loss: 0.312\n",
      "| steps 0020300 | Validation Accuracy: 0.351\n",
      "| steps 0020400 | loss: 0.344\n",
      "| steps 0020400 | Validation Accuracy: 0.439\n",
      "| steps 0020500 | loss: 0.312\n",
      "| steps 0020500 | Validation Accuracy: 0.368\n",
      "| steps 0020600 | loss: 0.250\n",
      "| steps 0020600 | Validation Accuracy: 0.386\n",
      "| steps 0020700 | loss: 0.281\n",
      "| steps 0020700 | Validation Accuracy: 0.421\n",
      "| steps 0020800 | loss: 0.219\n",
      "| steps 0020800 | Validation Accuracy: 0.368\n",
      "| steps 0020900 | loss: 0.188\n",
      "| steps 0020900 | Validation Accuracy: 0.439\n",
      "| steps 0021000 | loss: 0.312\n",
      "| steps 0021000 | Validation Accuracy: 0.368\n",
      "| steps 0021100 | loss: 0.469\n",
      "| steps 0021100 | Validation Accuracy: 0.439\n",
      "| steps 0021200 | loss: 0.500\n",
      "| steps 0021200 | Validation Accuracy: 0.333\n",
      "| steps 0021300 | loss: 0.281\n",
      "| steps 0021300 | Validation Accuracy: 0.474\n",
      "| steps 0021400 | loss: 0.406\n",
      "| steps 0021400 | Validation Accuracy: 0.368\n",
      "| steps 0021500 | loss: 0.219\n",
      "| steps 0021500 | Validation Accuracy: 0.439\n",
      "| steps 0021600 | loss: 0.281\n",
      "| steps 0021600 | Validation Accuracy: 0.439\n",
      "| steps 0021700 | loss: 0.281\n",
      "| steps 0021700 | Validation Accuracy: 0.368\n",
      "| steps 0021800 | loss: 0.281\n",
      "| steps 0021800 | Validation Accuracy: 0.456\n",
      "| steps 0021900 | loss: 0.406\n",
      "| steps 0021900 | Validation Accuracy: 0.351\n",
      "| steps 0022000 | loss: 0.250\n",
      "| steps 0022000 | Validation Accuracy: 0.333\n",
      "| steps 0022100 | loss: 0.250\n",
      "| steps 0022100 | Validation Accuracy: 0.474\n",
      "| steps 0022200 | loss: 0.344\n",
      "| steps 0022200 | Validation Accuracy: 0.439\n",
      "| steps 0022300 | loss: 0.406\n",
      "| steps 0022300 | Validation Accuracy: 0.368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| steps 0022400 | loss: 0.281\n",
      "| steps 0022400 | Validation Accuracy: 0.404\n",
      "| steps 0022500 | loss: 0.375\n",
      "| steps 0022500 | Validation Accuracy: 0.404\n",
      "| steps 0022600 | loss: 0.438\n",
      "| steps 0022600 | Validation Accuracy: 0.368\n",
      "| steps 0022700 | loss: 0.188\n",
      "| steps 0022700 | Validation Accuracy: 0.439\n",
      "| steps 0022800 | loss: 0.469\n",
      "| steps 0022800 | Validation Accuracy: 0.351\n",
      "| steps 0022900 | loss: 0.281\n",
      "| steps 0022900 | Validation Accuracy: 0.456\n",
      "| steps 0023000 | loss: 0.188\n",
      "| steps 0023000 | Validation Accuracy: 0.281\n",
      "| steps 0023100 | loss: 0.375\n",
      "| steps 0023100 | Validation Accuracy: 0.526\n",
      "| steps 0023200 | loss: 0.250\n",
      "| steps 0023200 | Validation Accuracy: 0.333\n",
      "| steps 0023300 | loss: 0.250\n",
      "| steps 0023300 | Validation Accuracy: 0.474\n",
      "| steps 0023400 | loss: 0.156\n",
      "| steps 0023400 | Validation Accuracy: 0.351\n",
      "| steps 0023500 | loss: 0.219\n",
      "| steps 0023500 | Validation Accuracy: 0.456\n",
      "| steps 0023600 | loss: 0.281\n",
      "| steps 0023600 | Validation Accuracy: 0.456\n",
      "| steps 0023700 | loss: 0.281\n",
      "| steps 0023700 | Validation Accuracy: 0.351\n",
      "| steps 0023800 | loss: 0.375\n",
      "| steps 0023800 | Validation Accuracy: 0.298\n",
      "| steps 0023900 | loss: 0.281\n",
      "| steps 0023900 | Validation Accuracy: 0.509\n",
      "| steps 0024000 | loss: 0.312\n",
      "| steps 0024000 | Validation Accuracy: 0.439\n",
      "| steps 0024100 | loss: 0.250\n",
      "| steps 0024100 | Validation Accuracy: 0.368\n",
      "| steps 0024200 | loss: 0.344\n",
      "| steps 0024200 | Validation Accuracy: 0.386\n",
      "| steps 0024300 | loss: 0.438\n",
      "| steps 0024300 | Validation Accuracy: 0.421\n",
      "| steps 0024400 | loss: 0.219\n",
      "| steps 0024400 | Validation Accuracy: 0.456\n",
      "| steps 0024500 | loss: 0.281\n",
      "| steps 0024500 | Validation Accuracy: 0.351\n",
      "| steps 0024600 | loss: 0.188\n",
      "| steps 0024600 | Validation Accuracy: 0.368\n",
      "| steps 0024700 | loss: 0.250\n",
      "| steps 0024700 | Validation Accuracy: 0.439\n",
      "| steps 0024800 | loss: 0.188\n",
      "| steps 0024800 | Validation Accuracy: 0.439\n",
      "| steps 0024900 | loss: 0.375\n",
      "| steps 0024900 | Validation Accuracy: 0.368\n",
      "| steps 0025000 | loss: 0.281\n",
      "| steps 0025000 | Validation Accuracy: 0.386\n",
      "| steps 0025100 | loss: 0.219\n",
      "| steps 0025100 | Validation Accuracy: 0.421\n",
      "| steps 0025200 | loss: 0.125\n",
      "| steps 0025200 | Validation Accuracy: 0.439\n",
      "| steps 0025300 | loss: 0.438\n",
      "| steps 0025300 | Validation Accuracy: 0.368\n",
      "| steps 0025400 | loss: 0.344\n",
      "| steps 0025400 | Validation Accuracy: 0.439\n",
      "| steps 0025500 | loss: 0.250\n",
      "| steps 0025500 | Validation Accuracy: 0.368\n",
      "| steps 0025600 | loss: 0.281\n",
      "| steps 0025600 | Validation Accuracy: 0.368\n",
      "| steps 0025700 | loss: 0.344\n",
      "| steps 0025700 | Validation Accuracy: 0.439\n",
      "| steps 0025800 | loss: 0.281\n",
      "| steps 0025800 | Validation Accuracy: 0.491\n",
      "| steps 0025900 | loss: 0.312\n",
      "| steps 0025900 | Validation Accuracy: 0.316\n",
      "| steps 0026000 | loss: 0.281\n",
      "| steps 0026000 | Validation Accuracy: 0.386\n",
      "| steps 0026100 | loss: 0.125\n",
      "| steps 0026100 | Validation Accuracy: 0.421\n",
      "| steps 0026200 | loss: 0.250\n",
      "| steps 0026200 | Validation Accuracy: 0.456\n",
      "| steps 0026300 | loss: 0.344\n",
      "| steps 0026300 | Validation Accuracy: 0.351\n",
      "| steps 0026400 | loss: 0.469\n",
      "| steps 0026400 | Validation Accuracy: 0.351\n",
      "| steps 0026500 | loss: 0.312\n",
      "| steps 0026500 | Validation Accuracy: 0.456\n",
      "| steps 0026600 | loss: 0.281\n",
      "| steps 0026600 | Validation Accuracy: 0.386\n",
      "| steps 0026700 | loss: 0.562\n",
      "| steps 0026700 | Validation Accuracy: 0.421\n",
      "| steps 0026800 | loss: 0.250\n",
      "| steps 0026800 | Validation Accuracy: 0.421\n",
      "| steps 0026900 | loss: 0.375\n",
      "| steps 0026900 | Validation Accuracy: 0.386\n",
      "| steps 0027000 | loss: 0.281\n",
      "| steps 0027000 | Validation Accuracy: 0.386\n",
      "| steps 0027100 | loss: 0.281\n",
      "| steps 0027100 | Validation Accuracy: 0.421\n",
      "| steps 0027200 | loss: 0.219\n",
      "| steps 0027200 | Validation Accuracy: 0.316\n",
      "| steps 0027300 | loss: 0.375\n",
      "| steps 0027300 | Validation Accuracy: 0.491\n",
      "| steps 0027400 | loss: 0.250\n",
      "| steps 0027400 | Validation Accuracy: 0.439\n",
      "| steps 0027500 | loss: 0.375\n",
      "| steps 0027500 | Validation Accuracy: 0.368\n",
      "| steps 0027600 | loss: 0.406\n",
      "| steps 0027600 | Validation Accuracy: 0.404\n",
      "| steps 0027700 | loss: 0.281\n",
      "| steps 0027700 | Validation Accuracy: 0.404\n",
      "| steps 0027800 | loss: 0.312\n",
      "| steps 0027800 | Validation Accuracy: 0.386\n",
      "| steps 0027900 | loss: 0.250\n",
      "| steps 0027900 | Validation Accuracy: 0.421\n",
      "| steps 0028000 | loss: 0.281\n",
      "| steps 0028000 | Validation Accuracy: 0.491\n",
      "| steps 0028100 | loss: 0.406\n",
      "| steps 0028100 | Validation Accuracy: 0.316\n",
      "| steps 0028200 | loss: 0.219\n",
      "| steps 0028200 | Validation Accuracy: 0.421\n",
      "| steps 0028300 | loss: 0.250\n",
      "| steps 0028300 | Validation Accuracy: 0.386\n",
      "| steps 0028400 | loss: 0.406\n",
      "| steps 0028400 | Validation Accuracy: 0.404\n",
      "| steps 0028500 | loss: 0.250\n",
      "| steps 0028500 | Validation Accuracy: 0.404\n",
      "| steps 0028600 | loss: 0.250\n",
      "| steps 0028600 | Validation Accuracy: 0.404\n",
      "| steps 0028700 | loss: 0.250\n",
      "| steps 0028700 | Validation Accuracy: 0.404\n",
      "| steps 0028800 | loss: 0.156\n",
      "| steps 0028800 | Validation Accuracy: 0.421\n",
      "| steps 0028900 | loss: 0.250\n",
      "| steps 0028900 | Validation Accuracy: 0.386\n",
      "| steps 0029000 | loss: 0.469\n",
      "| steps 0029000 | Validation Accuracy: 0.404\n",
      "| steps 0029100 | loss: 0.375\n",
      "| steps 0029100 | Validation Accuracy: 0.404\n",
      "| steps 0029200 | loss: 0.375\n",
      "| steps 0029200 | Validation Accuracy: 0.474\n",
      "| steps 0029300 | loss: 0.312\n",
      "| steps 0029300 | Validation Accuracy: 0.333\n",
      "| steps 0029400 | loss: 0.188\n",
      "| steps 0029400 | Validation Accuracy: 0.386\n",
      "| steps 0029500 | loss: 0.281\n",
      "| steps 0029500 | Validation Accuracy: 0.421\n",
      "| steps 0029600 | loss: 0.438\n",
      "| steps 0029600 | Validation Accuracy: 0.456\n",
      "| steps 0029700 | loss: 0.469\n",
      "| steps 0029700 | Validation Accuracy: 0.351\n",
      "| steps 0029800 | loss: 0.406\n",
      "| steps 0029800 | Validation Accuracy: 0.456\n",
      "| steps 0029900 | loss: 0.344\n",
      "| steps 0029900 | Validation Accuracy: 0.351\n",
      "| steps 0030000 | loss: 0.281\n",
      "| steps 0030000 | Validation Accuracy: 0.386\n",
      "| steps 0030100 | loss: 0.406\n",
      "| steps 0030100 | Validation Accuracy: 0.421\n",
      "| steps 0030200 | loss: 0.281\n",
      "| steps 0030200 | Validation Accuracy: 0.333\n",
      "| steps 0030300 | loss: 0.344\n",
      "| steps 0030300 | Validation Accuracy: 0.474\n",
      "| steps 0030400 | loss: 0.375\n",
      "| steps 0030400 | Validation Accuracy: 0.368\n",
      "| steps 0030500 | loss: 0.375\n",
      "| steps 0030500 | Validation Accuracy: 0.439\n",
      "| steps 0030600 | loss: 0.344\n",
      "| steps 0030600 | Validation Accuracy: 0.456\n",
      "| steps 0030700 | loss: 0.250\n",
      "| steps 0030700 | Validation Accuracy: 0.351\n",
      "| steps 0030800 | loss: 0.188\n",
      "| steps 0030800 | Validation Accuracy: 0.386\n",
      "| steps 0030900 | loss: 0.312\n",
      "| steps 0030900 | Validation Accuracy: 0.421\n",
      "| steps 0031000 | loss: 0.344\n",
      "| steps 0031000 | Validation Accuracy: 0.439\n",
      "| steps 0031100 | loss: 0.469\n",
      "| steps 0031100 | Validation Accuracy: 0.368\n",
      "| steps 0031200 | loss: 0.250\n",
      "| steps 0031200 | Validation Accuracy: 0.474\n",
      "| steps 0031300 | loss: 0.469\n",
      "| steps 0031300 | Validation Accuracy: 0.333\n",
      "| steps 0031400 | loss: 0.312\n",
      "| steps 0031400 | Validation Accuracy: 0.456\n",
      "| steps 0031500 | loss: 0.312\n",
      "| steps 0031500 | Validation Accuracy: 0.351\n",
      "| steps 0031600 | loss: 0.312\n",
      "| steps 0031600 | Validation Accuracy: 0.456\n",
      "| steps 0031700 | loss: 0.312\n",
      "| steps 0031700 | Validation Accuracy: 0.351\n",
      "| steps 0031800 | loss: 0.406\n",
      "| steps 0031800 | Validation Accuracy: 0.456\n",
      "| steps 0031900 | loss: 0.156\n",
      "| steps 0031900 | Validation Accuracy: 0.351\n",
      "| steps 0032000 | loss: 0.344\n",
      "| steps 0032000 | Validation Accuracy: 0.368\n",
      "| steps 0032100 | loss: 0.438\n",
      "| steps 0032100 | Validation Accuracy: 0.439\n",
      "| steps 0032200 | loss: 0.312\n",
      "| steps 0032200 | Validation Accuracy: 0.368\n",
      "| steps 0032300 | loss: 0.438\n",
      "| steps 0032300 | Validation Accuracy: 0.439\n",
      "| steps 0032400 | loss: 0.281\n",
      "| steps 0032400 | Validation Accuracy: 0.439\n",
      "| steps 0032500 | loss: 0.250\n",
      "| steps 0032500 | Validation Accuracy: 0.368\n",
      "| steps 0032600 | loss: 0.281\n",
      "| steps 0032600 | Validation Accuracy: 0.386\n",
      "| steps 0032700 | loss: 0.406\n",
      "| steps 0032700 | Validation Accuracy: 0.421\n",
      "| steps 0032800 | loss: 0.125\n",
      "| steps 0032800 | Validation Accuracy: 0.368\n",
      "| steps 0032900 | loss: 0.312\n",
      "| steps 0032900 | Validation Accuracy: 0.439\n",
      "| steps 0033000 | loss: 0.469\n",
      "| steps 0033000 | Validation Accuracy: 0.439\n",
      "| steps 0033100 | loss: 0.312\n",
      "| steps 0033100 | Validation Accuracy: 0.368\n",
      "| steps 0033200 | loss: 0.312\n",
      "| steps 0033200 | Validation Accuracy: 0.421\n",
      "| steps 0033300 | loss: 0.344\n",
      "| steps 0033300 | Validation Accuracy: 0.386\n",
      "| steps 0033400 | loss: 0.406\n",
      "| steps 0033400 | Validation Accuracy: 0.421\n",
      "| steps 0033500 | loss: 0.219\n",
      "| steps 0033500 | Validation Accuracy: 0.386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| steps 0033600 | loss: 0.281\n",
      "| steps 0033600 | Validation Accuracy: 0.333\n",
      "| steps 0033700 | loss: 0.312\n",
      "| steps 0033700 | Validation Accuracy: 0.474\n",
      "| steps 0033800 | loss: 0.281\n",
      "| steps 0033800 | Validation Accuracy: 0.421\n",
      "| steps 0033900 | loss: 0.188\n",
      "| steps 0033900 | Validation Accuracy: 0.386\n",
      "| steps 0034000 | loss: 0.438\n",
      "| steps 0034000 | Validation Accuracy: 0.333\n",
      "| steps 0034100 | loss: 0.250\n",
      "| steps 0034100 | Validation Accuracy: 0.474\n",
      "| steps 0034200 | loss: 0.344\n",
      "| steps 0034200 | Validation Accuracy: 0.439\n",
      "| steps 0034300 | loss: 0.344\n",
      "| steps 0034300 | Validation Accuracy: 0.368\n",
      "| steps 0034400 | loss: 0.250\n",
      "| steps 0034400 | Validation Accuracy: 0.386\n",
      "| steps 0034500 | loss: 0.312\n",
      "| steps 0034500 | Validation Accuracy: 0.421\n",
      "| steps 0034600 | loss: 0.406\n",
      "| steps 0034600 | Validation Accuracy: 0.474\n",
      "| steps 0034700 | loss: 0.281\n",
      "| steps 0034700 | Validation Accuracy: 0.333\n",
      "| steps 0034800 | loss: 0.344\n",
      "| steps 0034800 | Validation Accuracy: 0.456\n",
      "| steps 0034900 | loss: 0.281\n",
      "| steps 0034900 | Validation Accuracy: 0.351\n",
      "| steps 0035000 | loss: 0.281\n",
      "| steps 0035000 | Validation Accuracy: 0.421\n",
      "| steps 0035100 | loss: 0.344\n",
      "| steps 0035100 | Validation Accuracy: 0.386\n",
      "| steps 0035200 | loss: 0.406\n",
      "| steps 0035200 | Validation Accuracy: 0.404\n",
      "| steps 0035300 | loss: 0.344\n",
      "| steps 0035300 | Validation Accuracy: 0.404\n",
      "| steps 0035400 | loss: 0.375\n",
      "| steps 0035400 | Validation Accuracy: 0.421\n",
      "| steps 0035500 | loss: 0.344\n",
      "| steps 0035500 | Validation Accuracy: 0.386\n",
      "| steps 0035600 | loss: 0.406\n",
      "| steps 0035600 | Validation Accuracy: 0.386\n",
      "| steps 0035700 | loss: 0.312\n",
      "| steps 0035700 | Validation Accuracy: 0.421\n",
      "| steps 0035800 | loss: 0.250\n",
      "| steps 0035800 | Validation Accuracy: 0.386\n",
      "| steps 0035900 | loss: 0.344\n",
      "| steps 0035900 | Validation Accuracy: 0.421\n",
      "| steps 0036000 | loss: 0.188\n",
      "| steps 0036000 | Validation Accuracy: 0.404\n",
      "| steps 0036100 | loss: 0.344\n",
      "| steps 0036100 | Validation Accuracy: 0.404\n",
      "| steps 0036200 | loss: 0.406\n",
      "| steps 0036200 | Validation Accuracy: 0.281\n",
      "| steps 0036300 | loss: 0.344\n",
      "| steps 0036300 | Validation Accuracy: 0.526\n",
      "| steps 0036400 | loss: 0.406\n",
      "| steps 0036400 | Validation Accuracy: 0.474\n",
      "| steps 0036500 | loss: 0.438\n",
      "| steps 0036500 | Validation Accuracy: 0.333\n",
      "| steps 0036600 | loss: 0.281\n",
      "| steps 0036600 | Validation Accuracy: 0.474\n",
      "| steps 0036700 | loss: 0.344\n",
      "| steps 0036700 | Validation Accuracy: 0.333\n",
      "| steps 0036800 | loss: 0.188\n",
      "| steps 0036800 | Validation Accuracy: 0.386\n",
      "| steps 0036900 | loss: 0.438\n",
      "| steps 0036900 | Validation Accuracy: 0.421\n",
      "| steps 0037000 | loss: 0.312\n",
      "| steps 0037000 | Validation Accuracy: 0.386\n",
      "| steps 0037100 | loss: 0.219\n",
      "| steps 0037100 | Validation Accuracy: 0.421\n",
      "| steps 0037200 | loss: 0.250\n",
      "| steps 0037200 | Validation Accuracy: 0.439\n",
      "| steps 0037300 | loss: 0.531\n",
      "| steps 0037300 | Validation Accuracy: 0.368\n",
      "| steps 0037400 | loss: 0.219\n",
      "| steps 0037400 | Validation Accuracy: 0.333\n",
      "| steps 0037500 | loss: 0.344\n",
      "| steps 0037500 | Validation Accuracy: 0.474\n",
      "| steps 0037600 | loss: 0.375\n",
      "| steps 0037600 | Validation Accuracy: 0.421\n",
      "| steps 0037700 | loss: 0.438\n",
      "| steps 0037700 | Validation Accuracy: 0.386\n",
      "| steps 0037800 | loss: 0.312\n",
      "| steps 0037800 | Validation Accuracy: 0.368\n",
      "| steps 0037900 | loss: 0.312\n",
      "| steps 0037900 | Validation Accuracy: 0.439\n",
      "| steps 0038000 | loss: 0.375\n",
      "| steps 0038000 | Validation Accuracy: 0.456\n",
      "| steps 0038100 | loss: 0.469\n",
      "| steps 0038100 | Validation Accuracy: 0.351\n",
      "| steps 0038200 | loss: 0.219\n",
      "| steps 0038200 | Validation Accuracy: 0.368\n",
      "| steps 0038300 | loss: 0.406\n",
      "| steps 0038300 | Validation Accuracy: 0.439\n",
      "| steps 0038400 | loss: 0.281\n",
      "| steps 0038400 | Validation Accuracy: 0.351\n",
      "| steps 0038500 | loss: 0.156\n",
      "| steps 0038500 | Validation Accuracy: 0.456\n",
      "| steps 0038600 | loss: 0.281\n",
      "| steps 0038600 | Validation Accuracy: 0.456\n",
      "| steps 0038700 | loss: 0.188\n",
      "| steps 0038700 | Validation Accuracy: 0.351\n",
      "| steps 0038800 | loss: 0.344\n",
      "| steps 0038800 | Validation Accuracy: 0.386\n",
      "| steps 0038900 | loss: 0.188\n",
      "| steps 0038900 | Validation Accuracy: 0.421\n",
      "| steps 0039000 | loss: 0.406\n",
      "| steps 0039000 | Validation Accuracy: 0.439\n",
      "| steps 0039100 | loss: 0.375\n",
      "| steps 0039100 | Validation Accuracy: 0.368\n",
      "| steps 0039200 | loss: 0.312\n",
      "| steps 0039200 | Validation Accuracy: 0.456\n",
      "| steps 0039300 | loss: 0.219\n",
      "| steps 0039300 | Validation Accuracy: 0.351\n",
      "| steps 0039400 | loss: 0.531\n",
      "| steps 0039400 | Validation Accuracy: 0.386\n",
      "| steps 0039500 | loss: 0.250\n",
      "| steps 0039500 | Validation Accuracy: 0.421\n",
      "| steps 0039600 | loss: 0.375\n",
      "| steps 0039600 | Validation Accuracy: 0.439\n",
      "| steps 0039700 | loss: 0.250\n",
      "| steps 0039700 | Validation Accuracy: 0.368\n",
      "| steps 0039800 | loss: 0.188\n",
      "| steps 0039800 | Validation Accuracy: 0.333\n",
      "| steps 0039900 | loss: 0.438\n",
      "| steps 0039900 | Validation Accuracy: 0.474\n",
      "| steps 0040000 | loss: 0.312\n",
      "| steps 0040000 | Validation Accuracy: 0.404\n",
      "| steps 0040100 | loss: 0.438\n",
      "| steps 0040100 | Validation Accuracy: 0.404\n",
      "| steps 0040200 | loss: 0.250\n",
      "| steps 0040200 | Validation Accuracy: 0.491\n",
      "| steps 0040300 | loss: 0.406\n",
      "| steps 0040300 | Validation Accuracy: 0.316\n",
      "| steps 0040400 | loss: 0.375\n",
      "| steps 0040400 | Validation Accuracy: 0.456\n",
      "| steps 0040500 | loss: 0.438\n",
      "| steps 0040500 | Validation Accuracy: 0.351\n",
      "| steps 0040600 | loss: 0.250\n",
      "| steps 0040600 | Validation Accuracy: 0.368\n",
      "| steps 0040700 | loss: 0.562\n",
      "| steps 0040700 | Validation Accuracy: 0.439\n",
      "| steps 0040800 | loss: 0.375\n",
      "| steps 0040800 | Validation Accuracy: 0.421\n",
      "| steps 0040900 | loss: 0.375\n",
      "| steps 0040900 | Validation Accuracy: 0.386\n",
      "| steps 0041000 | loss: 0.344\n",
      "| steps 0041000 | Validation Accuracy: 0.421\n",
      "| steps 0041100 | loss: 0.156\n",
      "| steps 0041100 | Validation Accuracy: 0.386\n",
      "| steps 0041200 | loss: 0.250\n",
      "| steps 0041200 | Validation Accuracy: 0.404\n",
      "| steps 0041300 | loss: 0.312\n",
      "| steps 0041300 | Validation Accuracy: 0.404\n",
      "| steps 0041400 | loss: 0.312\n",
      "| steps 0041400 | Validation Accuracy: 0.456\n",
      "| steps 0041500 | loss: 0.406\n",
      "| steps 0041500 | Validation Accuracy: 0.351\n",
      "| steps 0041600 | loss: 0.312\n",
      "| steps 0041600 | Validation Accuracy: 0.386\n",
      "| steps 0041700 | loss: 0.250\n",
      "| steps 0041700 | Validation Accuracy: 0.421\n",
      "| steps 0041800 | loss: 0.250\n",
      "| steps 0041800 | Validation Accuracy: 0.386\n",
      "| steps 0041900 | loss: 0.250\n",
      "| steps 0041900 | Validation Accuracy: 0.421\n",
      "| steps 0042000 | loss: 0.375\n",
      "| steps 0042000 | Validation Accuracy: 0.351\n",
      "| steps 0042100 | loss: 0.344\n",
      "| steps 0042100 | Validation Accuracy: 0.456\n",
      "| steps 0042200 | loss: 0.375\n",
      "| steps 0042200 | Validation Accuracy: 0.439\n",
      "| steps 0042300 | loss: 0.344\n",
      "| steps 0042300 | Validation Accuracy: 0.368\n",
      "| steps 0042400 | loss: 0.312\n",
      "| steps 0042400 | Validation Accuracy: 0.386\n",
      "| steps 0042500 | loss: 0.312\n",
      "| steps 0042500 | Validation Accuracy: 0.421\n",
      "| steps 0042600 | loss: 0.281\n",
      "| steps 0042600 | Validation Accuracy: 0.386\n",
      "| steps 0042700 | loss: 0.438\n",
      "| steps 0042700 | Validation Accuracy: 0.421\n",
      "| steps 0042800 | loss: 0.312\n",
      "| steps 0042800 | Validation Accuracy: 0.439\n",
      "| steps 0042900 | loss: 0.250\n",
      "| steps 0042900 | Validation Accuracy: 0.368\n",
      "| steps 0043000 | loss: 0.438\n",
      "| steps 0043000 | Validation Accuracy: 0.474\n",
      "| steps 0043100 | loss: 0.281\n",
      "| steps 0043100 | Validation Accuracy: 0.333\n",
      "| steps 0043200 | loss: 0.438\n",
      "| steps 0043200 | Validation Accuracy: 0.333\n",
      "| steps 0043300 | loss: 0.188\n",
      "| steps 0043300 | Validation Accuracy: 0.474\n",
      "| steps 0043400 | loss: 0.344\n",
      "| steps 0043400 | Validation Accuracy: 0.404\n",
      "| steps 0043500 | loss: 0.531\n",
      "| steps 0043500 | Validation Accuracy: 0.404\n",
      "| steps 0043600 | loss: 0.375\n",
      "| steps 0043600 | Validation Accuracy: 0.351\n",
      "| steps 0043700 | loss: 0.281\n",
      "| steps 0043700 | Validation Accuracy: 0.456\n",
      "| steps 0043800 | loss: 0.281\n",
      "| steps 0043800 | Validation Accuracy: 0.351\n",
      "| steps 0043900 | loss: 0.156\n",
      "| steps 0043900 | Validation Accuracy: 0.456\n",
      "| steps 0044000 | loss: 0.250\n",
      "| steps 0044000 | Validation Accuracy: 0.474\n",
      "| steps 0044100 | loss: 0.344\n",
      "| steps 0044100 | Validation Accuracy: 0.333\n",
      "| steps 0044200 | loss: 0.375\n",
      "| steps 0044200 | Validation Accuracy: 0.404\n",
      "| steps 0044300 | loss: 0.188\n",
      "| steps 0044300 | Validation Accuracy: 0.404\n",
      "| steps 0044400 | loss: 0.344\n",
      "| steps 0044400 | Validation Accuracy: 0.456\n",
      "| steps 0044500 | loss: 0.281\n",
      "| steps 0044500 | Validation Accuracy: 0.351\n",
      "| steps 0044600 | loss: 0.312\n",
      "| steps 0044600 | Validation Accuracy: 0.404\n",
      "| steps 0044700 | loss: 0.188\n",
      "| steps 0044700 | Validation Accuracy: 0.404\n",
      "| steps 0044800 | loss: 0.344\n",
      "| steps 0044800 | Validation Accuracy: 0.333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| steps 0044900 | loss: 0.281\n",
      "| steps 0044900 | Validation Accuracy: 0.474\n",
      "| steps 0045000 | loss: 0.281\n",
      "| steps 0045000 | Validation Accuracy: 0.386\n",
      "| steps 0045100 | loss: 0.312\n",
      "| steps 0045100 | Validation Accuracy: 0.421\n",
      "| steps 0045200 | loss: 0.469\n",
      "| steps 0045200 | Validation Accuracy: 0.404\n",
      "| steps 0045300 | loss: 0.281\n",
      "| steps 0045300 | Validation Accuracy: 0.404\n",
      "| steps 0045400 | loss: 0.312\n",
      "| steps 0045400 | Validation Accuracy: 0.386\n",
      "| steps 0045500 | loss: 0.188\n",
      "| steps 0045500 | Validation Accuracy: 0.421\n",
      "| steps 0045600 | loss: 0.188\n",
      "| steps 0045600 | Validation Accuracy: 0.368\n",
      "| steps 0045700 | loss: 0.438\n",
      "| steps 0045700 | Validation Accuracy: 0.439\n",
      "| steps 0045800 | loss: 0.281\n",
      "| steps 0045800 | Validation Accuracy: 0.333\n",
      "| steps 0045900 | loss: 0.344\n",
      "| steps 0045900 | Validation Accuracy: 0.474\n",
      "| steps 0046000 | loss: 0.312\n",
      "| steps 0046000 | Validation Accuracy: 0.351\n",
      "| steps 0046100 | loss: 0.438\n",
      "| steps 0046100 | Validation Accuracy: 0.456\n",
      "| steps 0046200 | loss: 0.312\n",
      "| steps 0046200 | Validation Accuracy: 0.474\n",
      "| steps 0046300 | loss: 0.281\n",
      "| steps 0046300 | Validation Accuracy: 0.333\n",
      "| steps 0046400 | loss: 0.344\n",
      "| steps 0046400 | Validation Accuracy: 0.368\n",
      "| steps 0046500 | loss: 0.406\n",
      "| steps 0046500 | Validation Accuracy: 0.439\n",
      "| steps 0046600 | loss: 0.406\n",
      "| steps 0046600 | Validation Accuracy: 0.386\n",
      "| steps 0046700 | loss: 0.469\n",
      "| steps 0046700 | Validation Accuracy: 0.421\n",
      "| steps 0046800 | loss: 0.219\n",
      "| steps 0046800 | Validation Accuracy: 0.421\n",
      "| steps 0046900 | loss: 0.562\n",
      "| steps 0046900 | Validation Accuracy: 0.386\n",
      "| steps 0047000 | loss: 0.250\n",
      "| steps 0047000 | Validation Accuracy: 0.421\n",
      "| steps 0047100 | loss: 0.250\n",
      "| steps 0047100 | Validation Accuracy: 0.386\n",
      "| steps 0047200 | loss: 0.156\n",
      "| steps 0047200 | Validation Accuracy: 0.386\n",
      "| steps 0047300 | loss: 0.156\n",
      "| steps 0047300 | Validation Accuracy: 0.421\n",
      "| steps 0047400 | loss: 0.344\n",
      "| steps 0047400 | Validation Accuracy: 0.439\n",
      "| steps 0047500 | loss: 0.250\n",
      "| steps 0047500 | Validation Accuracy: 0.368\n",
      "| steps 0047600 | loss: 0.344\n",
      "| steps 0047600 | Validation Accuracy: 0.456\n",
      "| steps 0047700 | loss: 0.250\n",
      "| steps 0047700 | Validation Accuracy: 0.351\n",
      "| steps 0047800 | loss: 0.281\n",
      "| steps 0047800 | Validation Accuracy: 0.439\n",
      "| steps 0047900 | loss: 0.344\n",
      "| steps 0047900 | Validation Accuracy: 0.368\n",
      "| steps 0048000 | loss: 0.344\n",
      "| steps 0048000 | Validation Accuracy: 0.386\n",
      "| steps 0048100 | loss: 0.250\n",
      "| steps 0048100 | Validation Accuracy: 0.421\n",
      "| steps 0048200 | loss: 0.250\n",
      "| steps 0048200 | Validation Accuracy: 0.368\n",
      "| steps 0048300 | loss: 0.312\n",
      "| steps 0048300 | Validation Accuracy: 0.439\n",
      "| steps 0048400 | loss: 0.438\n",
      "| steps 0048400 | Validation Accuracy: 0.386\n",
      "| steps 0048500 | loss: 0.344\n",
      "| steps 0048500 | Validation Accuracy: 0.421\n",
      "| steps 0048600 | loss: 0.344\n",
      "| steps 0048600 | Validation Accuracy: 0.386\n",
      "| steps 0048700 | loss: 0.469\n",
      "| steps 0048700 | Validation Accuracy: 0.421\n",
      "| steps 0048800 | loss: 0.344\n",
      "| steps 0048800 | Validation Accuracy: 0.351\n",
      "| steps 0048900 | loss: 0.250\n",
      "| steps 0048900 | Validation Accuracy: 0.456\n",
      "| steps 0049000 | loss: 0.406\n",
      "| steps 0049000 | Validation Accuracy: 0.474\n",
      "| steps 0049100 | loss: 0.312\n",
      "| steps 0049100 | Validation Accuracy: 0.333\n",
      "| steps 0049200 | loss: 0.438\n",
      "| steps 0049200 | Validation Accuracy: 0.474\n",
      "| steps 0049300 | loss: 0.312\n",
      "| steps 0049300 | Validation Accuracy: 0.333\n",
      "| steps 0049400 | loss: 0.219\n",
      "| steps 0049400 | Validation Accuracy: 0.474\n",
      "| steps 0049500 | loss: 0.375\n",
      "| steps 0049500 | Validation Accuracy: 0.333\n",
      "| steps 0049600 | loss: 0.250\n",
      "| steps 0049600 | Validation Accuracy: 0.333\n",
      "| steps 0049700 | loss: 0.281\n",
      "| steps 0049700 | Validation Accuracy: 0.474\n",
      "| steps 0049800 | loss: 0.344\n",
      "| steps 0049800 | Validation Accuracy: 0.439\n",
      "| steps 0049900 | loss: 0.406\n",
      "| steps 0049900 | Validation Accuracy: 0.368\n",
      "| steps 0050000 | loss: 0.375\n",
      "| steps 0050000 | Validation Accuracy: 0.456\n",
      "| steps 0050100 | loss: 0.312\n",
      "| steps 0050100 | Validation Accuracy: 0.351\n",
      "| steps 0050200 | loss: 0.344\n",
      "| steps 0050200 | Validation Accuracy: 0.474\n",
      "| steps 0050300 | loss: 0.250\n",
      "| steps 0050300 | Validation Accuracy: 0.333\n",
      "| steps 0050400 | loss: 0.344\n",
      "| steps 0050400 | Validation Accuracy: 0.456\n",
      "| steps 0050500 | loss: 0.438\n",
      "| steps 0050500 | Validation Accuracy: 0.351\n",
      "| steps 0050600 | loss: 0.156\n",
      "| steps 0050600 | Validation Accuracy: 0.368\n",
      "| steps 0050700 | loss: 0.250\n",
      "| steps 0050700 | Validation Accuracy: 0.439\n",
      "| steps 0050800 | loss: 0.219\n",
      "| steps 0050800 | Validation Accuracy: 0.386\n",
      "| steps 0050900 | loss: 0.281\n",
      "| steps 0050900 | Validation Accuracy: 0.421\n",
      "| steps 0051000 | loss: 0.344\n",
      "| steps 0051000 | Validation Accuracy: 0.368\n",
      "| steps 0051100 | loss: 0.219\n",
      "| steps 0051100 | Validation Accuracy: 0.439\n",
      "| steps 0051200 | loss: 0.312\n",
      "| steps 0051200 | Validation Accuracy: 0.386\n",
      "| steps 0051300 | loss: 0.344\n",
      "| steps 0051300 | Validation Accuracy: 0.421\n",
      "| steps 0051400 | loss: 0.344\n",
      "| steps 0051400 | Validation Accuracy: 0.386\n",
      "| steps 0051500 | loss: 0.375\n",
      "| steps 0051500 | Validation Accuracy: 0.421\n",
      "| steps 0051600 | loss: 0.344\n",
      "| steps 0051600 | Validation Accuracy: 0.386\n",
      "| steps 0051700 | loss: 0.281\n",
      "| steps 0051700 | Validation Accuracy: 0.421\n",
      "| steps 0051800 | loss: 0.281\n",
      "| steps 0051800 | Validation Accuracy: 0.333\n",
      "| steps 0051900 | loss: 0.312\n",
      "| steps 0051900 | Validation Accuracy: 0.474\n",
      "| steps 0052000 | loss: 0.344\n",
      "| steps 0052000 | Validation Accuracy: 0.421\n",
      "| steps 0052100 | loss: 0.438\n",
      "| steps 0052100 | Validation Accuracy: 0.386\n",
      "| steps 0052200 | loss: 0.406\n",
      "| steps 0052200 | Validation Accuracy: 0.316\n",
      "| steps 0052300 | loss: 0.344\n",
      "| steps 0052300 | Validation Accuracy: 0.491\n",
      "| steps 0052400 | loss: 0.250\n",
      "| steps 0052400 | Validation Accuracy: 0.404\n",
      "| steps 0052500 | loss: 0.344\n",
      "| steps 0052500 | Validation Accuracy: 0.404\n",
      "| steps 0052600 | loss: 0.188\n",
      "| steps 0052600 | Validation Accuracy: 0.404\n",
      "| steps 0052700 | loss: 0.219\n",
      "| steps 0052700 | Validation Accuracy: 0.404\n",
      "| steps 0052800 | loss: 0.375\n",
      "| steps 0052800 | Validation Accuracy: 0.368\n",
      "| steps 0052900 | loss: 0.312\n",
      "| steps 0052900 | Validation Accuracy: 0.439\n",
      "| steps 0053000 | loss: 0.188\n",
      "| steps 0053000 | Validation Accuracy: 0.456\n",
      "| steps 0053100 | loss: 0.375\n",
      "| steps 0053100 | Validation Accuracy: 0.351\n",
      "| steps 0053200 | loss: 0.344\n",
      "| steps 0053200 | Validation Accuracy: 0.368\n",
      "| steps 0053300 | loss: 0.344\n",
      "| steps 0053300 | Validation Accuracy: 0.439\n",
      "| steps 0053400 | loss: 0.406\n",
      "| steps 0053400 | Validation Accuracy: 0.386\n",
      "| steps 0053500 | loss: 0.375\n",
      "| steps 0053500 | Validation Accuracy: 0.421\n",
      "| steps 0053600 | loss: 0.344\n",
      "| steps 0053600 | Validation Accuracy: 0.421\n",
      "| steps 0053700 | loss: 0.438\n",
      "| steps 0053700 | Validation Accuracy: 0.386\n",
      "| steps 0053800 | loss: 0.312\n",
      "| steps 0053800 | Validation Accuracy: 0.316\n",
      "| steps 0053900 | loss: 0.219\n",
      "| steps 0053900 | Validation Accuracy: 0.491\n",
      "| steps 0054000 | loss: 0.156\n",
      "| steps 0054000 | Validation Accuracy: 0.333\n",
      "| steps 0054100 | loss: 0.250\n",
      "| steps 0054100 | Validation Accuracy: 0.474\n",
      "| steps 0054200 | loss: 0.312\n",
      "| steps 0054200 | Validation Accuracy: 0.386\n",
      "| steps 0054300 | loss: 0.344\n",
      "| steps 0054300 | Validation Accuracy: 0.421\n",
      "| steps 0054400 | loss: 0.406\n",
      "| steps 0054400 | Validation Accuracy: 0.404\n",
      "| steps 0054500 | loss: 0.375\n",
      "| steps 0054500 | Validation Accuracy: 0.404\n",
      "| steps 0054600 | loss: 0.250\n",
      "| steps 0054600 | Validation Accuracy: 0.491\n",
      "| steps 0054700 | loss: 0.219\n",
      "| steps 0054700 | Validation Accuracy: 0.316\n",
      "| steps 0054800 | loss: 0.406\n",
      "| steps 0054800 | Validation Accuracy: 0.439\n",
      "| steps 0054900 | loss: 0.375\n",
      "| steps 0054900 | Validation Accuracy: 0.368\n",
      "| steps 0055000 | loss: 0.281\n",
      "| steps 0055000 | Validation Accuracy: 0.404\n",
      "| steps 0055100 | loss: 0.219\n",
      "| steps 0055100 | Validation Accuracy: 0.404\n",
      "| steps 0055200 | loss: 0.312\n",
      "| steps 0055200 | Validation Accuracy: 0.421\n",
      "| steps 0055300 | loss: 0.375\n",
      "| steps 0055300 | Validation Accuracy: 0.386\n",
      "| steps 0055400 | loss: 0.219\n",
      "| steps 0055400 | Validation Accuracy: 0.386\n",
      "| steps 0055500 | loss: 0.219\n",
      "| steps 0055500 | Validation Accuracy: 0.421\n",
      "| steps 0055600 | loss: 0.344\n",
      "| steps 0055600 | Validation Accuracy: 0.386\n",
      "| steps 0055700 | loss: 0.219\n",
      "| steps 0055700 | Validation Accuracy: 0.421\n",
      "| steps 0055800 | loss: 0.312\n",
      "| steps 0055800 | Validation Accuracy: 0.368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| steps 0055900 | loss: 0.469\n",
      "| steps 0055900 | Validation Accuracy: 0.439\n",
      "| steps 0056000 | loss: 0.250\n",
      "| steps 0056000 | Validation Accuracy: 0.439\n",
      "| steps 0056100 | loss: 0.375\n",
      "| steps 0056100 | Validation Accuracy: 0.368\n",
      "| steps 0056200 | loss: 0.312\n",
      "| steps 0056200 | Validation Accuracy: 0.386\n",
      "| steps 0056300 | loss: 0.219\n",
      "| steps 0056300 | Validation Accuracy: 0.421\n",
      "| steps 0056400 | loss: 0.062\n",
      "| steps 0056400 | Validation Accuracy: 0.456\n",
      "| steps 0056500 | loss: 0.312\n",
      "| steps 0056500 | Validation Accuracy: 0.351\n",
      "| steps 0056600 | loss: 0.250\n",
      "| steps 0056600 | Validation Accuracy: 0.333\n",
      "| steps 0056700 | loss: 0.219\n",
      "| steps 0056700 | Validation Accuracy: 0.474\n",
      "| steps 0056800 | loss: 0.438\n",
      "| steps 0056800 | Validation Accuracy: 0.439\n",
      "| steps 0056900 | loss: 0.250\n",
      "| steps 0056900 | Validation Accuracy: 0.368\n",
      "| steps 0057000 | loss: 0.281\n",
      "| steps 0057000 | Validation Accuracy: 0.386\n",
      "| steps 0057100 | loss: 0.312\n",
      "| steps 0057100 | Validation Accuracy: 0.421\n",
      "| steps 0057200 | loss: 0.344\n",
      "| steps 0057200 | Validation Accuracy: 0.421\n",
      "| steps 0057300 | loss: 0.406\n",
      "| steps 0057300 | Validation Accuracy: 0.386\n",
      "| steps 0057400 | loss: 0.281\n",
      "| steps 0057400 | Validation Accuracy: 0.526\n",
      "| steps 0057500 | loss: 0.344\n",
      "| steps 0057500 | Validation Accuracy: 0.281\n",
      "| steps 0057600 | loss: 0.312\n",
      "| steps 0057600 | Validation Accuracy: 0.421\n",
      "| steps 0057700 | loss: 0.219\n",
      "| steps 0057700 | Validation Accuracy: 0.386\n",
      "| steps 0057800 | loss: 0.250\n",
      "| steps 0057800 | Validation Accuracy: 0.421\n",
      "| steps 0057900 | loss: 0.312\n",
      "| steps 0057900 | Validation Accuracy: 0.386\n",
      "| steps 0058000 | loss: 0.219\n",
      "| steps 0058000 | Validation Accuracy: 0.351\n",
      "| steps 0058100 | loss: 0.375\n",
      "| steps 0058100 | Validation Accuracy: 0.456\n",
      "| steps 0058200 | loss: 0.312\n",
      "| steps 0058200 | Validation Accuracy: 0.404\n",
      "| steps 0058300 | loss: 0.281\n",
      "| steps 0058300 | Validation Accuracy: 0.404\n",
      "| steps 0058400 | loss: 0.344\n",
      "| steps 0058400 | Validation Accuracy: 0.456\n",
      "| steps 0058500 | loss: 0.406\n",
      "| steps 0058500 | Validation Accuracy: 0.351\n",
      "| steps 0058600 | loss: 0.438\n",
      "| steps 0058600 | Validation Accuracy: 0.439\n",
      "| steps 0058700 | loss: 0.312\n",
      "| steps 0058700 | Validation Accuracy: 0.368\n",
      "| steps 0058800 | loss: 0.281\n",
      "| steps 0058800 | Validation Accuracy: 0.333\n",
      "| steps 0058900 | loss: 0.344\n",
      "| steps 0058900 | Validation Accuracy: 0.474\n",
      "| steps 0059000 | loss: 0.219\n",
      "| steps 0059000 | Validation Accuracy: 0.456\n",
      "| steps 0059100 | loss: 0.375\n",
      "| steps 0059100 | Validation Accuracy: 0.351\n",
      "| steps 0059200 | loss: 0.250\n",
      "| steps 0059200 | Validation Accuracy: 0.421\n",
      "| steps 0059300 | loss: 0.312\n",
      "| steps 0059300 | Validation Accuracy: 0.386\n",
      "| steps 0059400 | loss: 0.375\n",
      "| steps 0059400 | Validation Accuracy: 0.351\n",
      "| steps 0059500 | loss: 0.250\n",
      "| steps 0059500 | Validation Accuracy: 0.456\n",
      "| steps 0059600 | loss: 0.312\n",
      "| steps 0059600 | Validation Accuracy: 0.421\n",
      "| steps 0059700 | loss: 0.344\n",
      "| steps 0059700 | Validation Accuracy: 0.386\n",
      "| steps 0059800 | loss: 0.375\n",
      "| steps 0059800 | Validation Accuracy: 0.351\n",
      "| steps 0059900 | loss: 0.281\n",
      "| steps 0059900 | Validation Accuracy: 0.456\n",
      "| steps 0060000 | loss: 0.219\n",
      "| steps 0060000 | Validation Accuracy: 0.368\n",
      "| steps 0060100 | loss: 0.344\n",
      "| steps 0060100 | Validation Accuracy: 0.439\n",
      "| steps 0060200 | loss: 0.312\n",
      "| steps 0060200 | Validation Accuracy: 0.386\n",
      "| steps 0060300 | loss: 0.375\n",
      "| steps 0060300 | Validation Accuracy: 0.421\n",
      "| steps 0060400 | loss: 0.469\n",
      "| steps 0060400 | Validation Accuracy: 0.456\n",
      "| steps 0060500 | loss: 0.344\n",
      "| steps 0060500 | Validation Accuracy: 0.351\n",
      "| steps 0060600 | loss: 0.312\n",
      "| steps 0060600 | Validation Accuracy: 0.421\n",
      "| steps 0060700 | loss: 0.406\n",
      "| steps 0060700 | Validation Accuracy: 0.386\n",
      "| steps 0060800 | loss: 0.500\n",
      "| steps 0060800 | Validation Accuracy: 0.474\n",
      "| steps 0060900 | loss: 0.375\n",
      "| steps 0060900 | Validation Accuracy: 0.333\n",
      "| steps 0061000 | loss: 0.250\n",
      "| steps 0061000 | Validation Accuracy: 0.404\n",
      "| steps 0061100 | loss: 0.594\n",
      "| steps 0061100 | Validation Accuracy: 0.404\n",
      "| steps 0061200 | loss: 0.312\n",
      "| steps 0061200 | Validation Accuracy: 0.439\n",
      "| steps 0061300 | loss: 0.344\n",
      "| steps 0061300 | Validation Accuracy: 0.368\n",
      "| steps 0061400 | loss: 0.375\n",
      "| steps 0061400 | Validation Accuracy: 0.439\n",
      "| steps 0061500 | loss: 0.219\n",
      "| steps 0061500 | Validation Accuracy: 0.368\n",
      "| steps 0061600 | loss: 0.312\n",
      "| steps 0061600 | Validation Accuracy: 0.351\n",
      "| steps 0061700 | loss: 0.250\n",
      "| steps 0061700 | Validation Accuracy: 0.456\n",
      "| steps 0061800 | loss: 0.281\n",
      "| steps 0061800 | Validation Accuracy: 0.421\n",
      "| steps 0061900 | loss: 0.312\n",
      "| steps 0061900 | Validation Accuracy: 0.386\n",
      "| steps 0062000 | loss: 0.375\n",
      "| steps 0062000 | Validation Accuracy: 0.404\n",
      "| steps 0062100 | loss: 0.406\n",
      "| steps 0062100 | Validation Accuracy: 0.404\n",
      "| steps 0062200 | loss: 0.438\n",
      "| steps 0062200 | Validation Accuracy: 0.421\n",
      "| steps 0062300 | loss: 0.188\n",
      "| steps 0062300 | Validation Accuracy: 0.386\n",
      "| steps 0062400 | loss: 0.375\n",
      "| steps 0062400 | Validation Accuracy: 0.368\n",
      "| steps 0062500 | loss: 0.375\n",
      "| steps 0062500 | Validation Accuracy: 0.439\n",
      "| steps 0062600 | loss: 0.469\n",
      "| steps 0062600 | Validation Accuracy: 0.439\n",
      "| steps 0062700 | loss: 0.375\n",
      "| steps 0062700 | Validation Accuracy: 0.368\n",
      "| steps 0062800 | loss: 0.406\n",
      "| steps 0062800 | Validation Accuracy: 0.509\n",
      "| steps 0062900 | loss: 0.250\n",
      "| steps 0062900 | Validation Accuracy: 0.298\n",
      "| steps 0063000 | loss: 0.312\n",
      "| steps 0063000 | Validation Accuracy: 0.351\n",
      "| steps 0063100 | loss: 0.156\n",
      "| steps 0063100 | Validation Accuracy: 0.456\n",
      "| steps 0063200 | loss: 0.312\n",
      "| steps 0063200 | Validation Accuracy: 0.351\n",
      "| steps 0063300 | loss: 0.156\n",
      "| steps 0063300 | Validation Accuracy: 0.456\n",
      "| steps 0063400 | loss: 0.312\n",
      "| steps 0063400 | Validation Accuracy: 0.386\n",
      "| steps 0063500 | loss: 0.250\n",
      "| steps 0063500 | Validation Accuracy: 0.421\n",
      "| steps 0063600 | loss: 0.156\n",
      "| steps 0063600 | Validation Accuracy: 0.509\n",
      "| steps 0063700 | loss: 0.188\n",
      "| steps 0063700 | Validation Accuracy: 0.298\n",
      "| steps 0063800 | loss: 0.375\n",
      "| steps 0063800 | Validation Accuracy: 0.421\n",
      "| steps 0063900 | loss: 0.219\n",
      "| steps 0063900 | Validation Accuracy: 0.386\n",
      "| steps 0064000 | loss: 0.188\n",
      "| steps 0064000 | Validation Accuracy: 0.386\n",
      "| steps 0064100 | loss: 0.469\n",
      "| steps 0064100 | Validation Accuracy: 0.421\n",
      "| steps 0064200 | loss: 0.312\n",
      "| steps 0064200 | Validation Accuracy: 0.439\n",
      "| steps 0064300 | loss: 0.500\n",
      "| steps 0064300 | Validation Accuracy: 0.368\n",
      "| steps 0064400 | loss: 0.219\n",
      "| steps 0064400 | Validation Accuracy: 0.439\n",
      "| steps 0064500 | loss: 0.156\n",
      "| steps 0064500 | Validation Accuracy: 0.368\n",
      "| steps 0064600 | loss: 0.375\n",
      "| steps 0064600 | Validation Accuracy: 0.439\n",
      "| steps 0064700 | loss: 0.344\n",
      "| steps 0064700 | Validation Accuracy: 0.368\n",
      "| steps 0064800 | loss: 0.312\n",
      "| steps 0064800 | Validation Accuracy: 0.351\n",
      "| steps 0064900 | loss: 0.406\n",
      "| steps 0064900 | Validation Accuracy: 0.456\n",
      "| steps 0065000 | loss: 0.188\n",
      "| steps 0065000 | Validation Accuracy: 0.386\n",
      "| steps 0065100 | loss: 0.312\n",
      "| steps 0065100 | Validation Accuracy: 0.421\n",
      "| steps 0065200 | loss: 0.344\n",
      "| steps 0065200 | Validation Accuracy: 0.316\n",
      "| steps 0065300 | loss: 0.312\n",
      "| steps 0065300 | Validation Accuracy: 0.491\n",
      "| steps 0065400 | loss: 0.281\n",
      "| steps 0065400 | Validation Accuracy: 0.404\n",
      "| steps 0065500 | loss: 0.406\n",
      "| steps 0065500 | Validation Accuracy: 0.404\n",
      "| steps 0065600 | loss: 0.469\n",
      "| steps 0065600 | Validation Accuracy: 0.421\n",
      "| steps 0065700 | loss: 0.375\n",
      "| steps 0065700 | Validation Accuracy: 0.386\n",
      "| steps 0065800 | loss: 0.312\n",
      "| steps 0065800 | Validation Accuracy: 0.368\n",
      "| steps 0065900 | loss: 0.281\n",
      "| steps 0065900 | Validation Accuracy: 0.439\n",
      "| steps 0066000 | loss: 0.219\n",
      "| steps 0066000 | Validation Accuracy: 0.368\n",
      "| steps 0066100 | loss: 0.312\n",
      "| steps 0066100 | Validation Accuracy: 0.439\n",
      "| steps 0066200 | loss: 0.312\n",
      "| steps 0066200 | Validation Accuracy: 0.474\n",
      "| steps 0066300 | loss: 0.500\n",
      "| steps 0066300 | Validation Accuracy: 0.333\n",
      "| steps 0066400 | loss: 0.406\n",
      "| steps 0066400 | Validation Accuracy: 0.386\n",
      "| steps 0066500 | loss: 0.344\n",
      "| steps 0066500 | Validation Accuracy: 0.421\n",
      "| steps 0066600 | loss: 0.281\n",
      "| steps 0066600 | Validation Accuracy: 0.368\n",
      "| steps 0066700 | loss: 0.281\n",
      "| steps 0066700 | Validation Accuracy: 0.439\n",
      "| steps 0066800 | loss: 0.281\n",
      "| steps 0066800 | Validation Accuracy: 0.368\n",
      "| steps 0066900 | loss: 0.375\n",
      "| steps 0066900 | Validation Accuracy: 0.439\n",
      "| steps 0067000 | loss: 0.344\n",
      "| steps 0067000 | Validation Accuracy: 0.404\n",
      "| steps 0067100 | loss: 0.281\n",
      "| steps 0067100 | Validation Accuracy: 0.404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| steps 0067200 | loss: 0.250\n",
      "| steps 0067200 | Validation Accuracy: 0.526\n",
      "| steps 0067300 | loss: 0.375\n",
      "| steps 0067300 | Validation Accuracy: 0.281\n",
      "| steps 0067400 | loss: 0.250\n",
      "| steps 0067400 | Validation Accuracy: 0.386\n",
      "| steps 0067500 | loss: 0.312\n",
      "| steps 0067500 | Validation Accuracy: 0.421\n",
      "| steps 0067600 | loss: 0.250\n",
      "| steps 0067600 | Validation Accuracy: 0.351\n",
      "| steps 0067700 | loss: 0.281\n",
      "| steps 0067700 | Validation Accuracy: 0.456\n",
      "| steps 0067800 | loss: 0.219\n",
      "| steps 0067800 | Validation Accuracy: 0.439\n",
      "| steps 0067900 | loss: 0.406\n",
      "| steps 0067900 | Validation Accuracy: 0.368\n",
      "| steps 0068000 | loss: 0.375\n",
      "| steps 0068000 | Validation Accuracy: 0.368\n",
      "| steps 0068100 | loss: 0.312\n",
      "| steps 0068100 | Validation Accuracy: 0.439\n",
      "| steps 0068200 | loss: 0.219\n",
      "| steps 0068200 | Validation Accuracy: 0.386\n",
      "| steps 0068300 | loss: 0.250\n",
      "| steps 0068300 | Validation Accuracy: 0.421\n",
      "| steps 0068400 | loss: 0.438\n",
      "| steps 0068400 | Validation Accuracy: 0.386\n",
      "| steps 0068500 | loss: 0.438\n",
      "| steps 0068500 | Validation Accuracy: 0.421\n",
      "| steps 0068600 | loss: 0.188\n",
      "| steps 0068600 | Validation Accuracy: 0.404\n",
      "| steps 0068700 | loss: 0.344\n",
      "| steps 0068700 | Validation Accuracy: 0.404\n",
      "| steps 0068800 | loss: 0.219\n",
      "| steps 0068800 | Validation Accuracy: 0.351\n",
      "| steps 0068900 | loss: 0.312\n",
      "| steps 0068900 | Validation Accuracy: 0.456\n",
      "| steps 0069000 | loss: 0.156\n",
      "| steps 0069000 | Validation Accuracy: 0.491\n",
      "| steps 0069100 | loss: 0.375\n",
      "| steps 0069100 | Validation Accuracy: 0.316\n",
      "| steps 0069200 | loss: 0.312\n",
      "| steps 0069200 | Validation Accuracy: 0.421\n",
      "| steps 0069300 | loss: 0.125\n",
      "| steps 0069300 | Validation Accuracy: 0.386\n",
      "| steps 0069400 | loss: 0.281\n",
      "| steps 0069400 | Validation Accuracy: 0.456\n",
      "| steps 0069500 | loss: 0.219\n",
      "| steps 0069500 | Validation Accuracy: 0.351\n",
      "| steps 0069600 | loss: 0.312\n",
      "| steps 0069600 | Validation Accuracy: 0.439\n",
      "| steps 0069700 | loss: 0.281\n",
      "| steps 0069700 | Validation Accuracy: 0.368\n",
      "| steps 0069800 | loss: 0.312\n",
      "| steps 0069800 | Validation Accuracy: 0.298\n",
      "| steps 0069900 | loss: 0.438\n",
      "| steps 0069900 | Validation Accuracy: 0.509\n",
      "| steps 0070000 | loss: 0.344\n",
      "| steps 0070000 | Validation Accuracy: 0.456\n",
      "| steps 0070100 | loss: 0.344\n",
      "| steps 0070100 | Validation Accuracy: 0.351\n",
      "| steps 0070200 | loss: 0.344\n",
      "| steps 0070200 | Validation Accuracy: 0.456\n",
      "| steps 0070300 | loss: 0.281\n",
      "| steps 0070300 | Validation Accuracy: 0.351\n",
      "| steps 0070400 | loss: 0.344\n",
      "| steps 0070400 | Validation Accuracy: 0.404\n",
      "| steps 0070500 | loss: 0.125\n",
      "| steps 0070500 | Validation Accuracy: 0.404\n",
      "| steps 0070600 | loss: 0.156\n",
      "| steps 0070600 | Validation Accuracy: 0.351\n",
      "| steps 0070700 | loss: 0.344\n",
      "| steps 0070700 | Validation Accuracy: 0.456\n",
      "| steps 0070800 | loss: 0.281\n",
      "| steps 0070800 | Validation Accuracy: 0.368\n",
      "| steps 0070900 | loss: 0.281\n",
      "| steps 0070900 | Validation Accuracy: 0.439\n",
      "| steps 0071000 | loss: 0.344\n",
      "| steps 0071000 | Validation Accuracy: 0.474\n",
      "| steps 0071100 | loss: 0.344\n",
      "| steps 0071100 | Validation Accuracy: 0.333\n",
      "| steps 0071200 | loss: 0.438\n",
      "| steps 0071200 | Validation Accuracy: 0.404\n",
      "| steps 0071300 | loss: 0.312\n",
      "| steps 0071300 | Validation Accuracy: 0.404\n",
      "| steps 0071400 | loss: 0.250\n",
      "| steps 0071400 | Validation Accuracy: 0.456\n",
      "| steps 0071500 | loss: 0.469\n",
      "| steps 0071500 | Validation Accuracy: 0.351\n",
      "| steps 0071600 | loss: 0.406\n",
      "| steps 0071600 | Validation Accuracy: 0.421\n",
      "| steps 0071700 | loss: 0.344\n",
      "| steps 0071700 | Validation Accuracy: 0.386\n",
      "| steps 0071800 | loss: 0.312\n",
      "| steps 0071800 | Validation Accuracy: 0.439\n",
      "| steps 0071900 | loss: 0.312\n",
      "| steps 0071900 | Validation Accuracy: 0.368\n",
      "| steps 0072000 | loss: 0.219\n",
      "| steps 0072000 | Validation Accuracy: 0.421\n",
      "| steps 0072100 | loss: 0.469\n",
      "| steps 0072100 | Validation Accuracy: 0.386\n",
      "| steps 0072200 | loss: 0.312\n",
      "| steps 0072200 | Validation Accuracy: 0.421\n",
      "| steps 0072300 | loss: 0.312\n",
      "| steps 0072300 | Validation Accuracy: 0.386\n",
      "| steps 0072400 | loss: 0.438\n",
      "| steps 0072400 | Validation Accuracy: 0.404\n",
      "| steps 0072500 | loss: 0.344\n",
      "| steps 0072500 | Validation Accuracy: 0.404\n",
      "| steps 0072600 | loss: 0.156\n",
      "| steps 0072600 | Validation Accuracy: 0.421\n",
      "| steps 0072700 | loss: 0.312\n",
      "| steps 0072700 | Validation Accuracy: 0.386\n",
      "| steps 0072800 | loss: 0.375\n",
      "| steps 0072800 | Validation Accuracy: 0.368\n",
      "| steps 0072900 | loss: 0.344\n",
      "| steps 0072900 | Validation Accuracy: 0.439\n",
      "| steps 0073000 | loss: 0.219\n",
      "| steps 0073000 | Validation Accuracy: 0.421\n",
      "| steps 0073100 | loss: 0.312\n",
      "| steps 0073100 | Validation Accuracy: 0.386\n",
      "| steps 0073200 | loss: 0.125\n",
      "| steps 0073200 | Validation Accuracy: 0.421\n",
      "| steps 0073300 | loss: 0.281\n",
      "| steps 0073300 | Validation Accuracy: 0.386\n",
      "| steps 0073400 | loss: 0.469\n",
      "| steps 0073400 | Validation Accuracy: 0.333\n",
      "| steps 0073500 | loss: 0.188\n",
      "| steps 0073500 | Validation Accuracy: 0.474\n",
      "| steps 0073600 | loss: 0.156\n",
      "| steps 0073600 | Validation Accuracy: 0.421\n",
      "| steps 0073700 | loss: 0.188\n",
      "| steps 0073700 | Validation Accuracy: 0.386\n",
      "| steps 0073800 | loss: 0.375\n",
      "| steps 0073800 | Validation Accuracy: 0.404\n",
      "| steps 0073900 | loss: 0.219\n",
      "| steps 0073900 | Validation Accuracy: 0.404\n",
      "| steps 0074000 | loss: 0.219\n",
      "| steps 0074000 | Validation Accuracy: 0.404\n",
      "| steps 0074100 | loss: 0.219\n",
      "| steps 0074100 | Validation Accuracy: 0.404\n",
      "| steps 0074200 | loss: 0.312\n",
      "| steps 0074200 | Validation Accuracy: 0.509\n",
      "| steps 0074300 | loss: 0.344\n",
      "| steps 0074300 | Validation Accuracy: 0.298\n",
      "| steps 0074400 | loss: 0.312\n",
      "| steps 0074400 | Validation Accuracy: 0.404\n",
      "| steps 0074500 | loss: 0.125\n",
      "| steps 0074500 | Validation Accuracy: 0.404\n",
      "| steps 0074600 | loss: 0.250\n",
      "| steps 0074600 | Validation Accuracy: 0.386\n",
      "| steps 0074700 | loss: 0.250\n",
      "| steps 0074700 | Validation Accuracy: 0.421\n",
      "| steps 0074800 | loss: 0.281\n",
      "| steps 0074800 | Validation Accuracy: 0.439\n",
      "| steps 0074900 | loss: 0.219\n",
      "| steps 0074900 | Validation Accuracy: 0.368\n",
      "| steps 0075000 | loss: 0.438\n",
      "| steps 0075000 | Validation Accuracy: 0.386\n",
      "| steps 0075100 | loss: 0.344\n",
      "| steps 0075100 | Validation Accuracy: 0.421\n",
      "| steps 0075200 | loss: 0.250\n",
      "| steps 0075200 | Validation Accuracy: 0.456\n",
      "| steps 0075300 | loss: 0.312\n",
      "| steps 0075300 | Validation Accuracy: 0.351\n",
      "| steps 0075400 | loss: 0.281\n",
      "| steps 0075400 | Validation Accuracy: 0.386\n",
      "| steps 0075500 | loss: 0.281\n",
      "| steps 0075500 | Validation Accuracy: 0.421\n",
      "| steps 0075600 | loss: 0.312\n",
      "| steps 0075600 | Validation Accuracy: 0.474\n",
      "| steps 0075700 | loss: 0.281\n",
      "| steps 0075700 | Validation Accuracy: 0.333\n",
      "| steps 0075800 | loss: 0.312\n",
      "| steps 0075800 | Validation Accuracy: 0.368\n",
      "| steps 0075900 | loss: 0.344\n",
      "| steps 0075900 | Validation Accuracy: 0.439\n",
      "| steps 0076000 | loss: 0.281\n",
      "| steps 0076000 | Validation Accuracy: 0.509\n",
      "| steps 0076100 | loss: 0.375\n",
      "| steps 0076100 | Validation Accuracy: 0.298\n",
      "| steps 0076200 | loss: 0.312\n",
      "| steps 0076200 | Validation Accuracy: 0.368\n",
      "| steps 0076300 | loss: 0.219\n",
      "| steps 0076300 | Validation Accuracy: 0.439\n",
      "| steps 0076400 | loss: 0.156\n",
      "| steps 0076400 | Validation Accuracy: 0.404\n",
      "| steps 0076500 | loss: 0.281\n",
      "| steps 0076500 | Validation Accuracy: 0.404\n",
      "| steps 0076600 | loss: 0.344\n",
      "| steps 0076600 | Validation Accuracy: 0.386\n",
      "| steps 0076700 | loss: 0.469\n",
      "| steps 0076700 | Validation Accuracy: 0.421\n",
      "| steps 0076800 | loss: 0.156\n",
      "| steps 0076800 | Validation Accuracy: 0.474\n",
      "| steps 0076900 | loss: 0.219\n",
      "| steps 0076900 | Validation Accuracy: 0.333\n",
      "| steps 0077000 | loss: 0.344\n",
      "| steps 0077000 | Validation Accuracy: 0.368\n",
      "| steps 0077100 | loss: 0.312\n",
      "| steps 0077100 | Validation Accuracy: 0.439\n",
      "| steps 0077200 | loss: 0.344\n",
      "| steps 0077200 | Validation Accuracy: 0.421\n",
      "| steps 0077300 | loss: 0.250\n",
      "| steps 0077300 | Validation Accuracy: 0.386\n",
      "| steps 0077400 | loss: 0.312\n",
      "| steps 0077400 | Validation Accuracy: 0.351\n",
      "| steps 0077500 | loss: 0.375\n",
      "| steps 0077500 | Validation Accuracy: 0.456\n",
      "| steps 0077600 | loss: 0.344\n",
      "| steps 0077600 | Validation Accuracy: 0.368\n",
      "| steps 0077700 | loss: 0.375\n",
      "| steps 0077700 | Validation Accuracy: 0.439\n",
      "| steps 0077800 | loss: 0.219\n",
      "| steps 0077800 | Validation Accuracy: 0.456\n",
      "| steps 0077900 | loss: 0.281\n",
      "| steps 0077900 | Validation Accuracy: 0.351\n",
      "| steps 0078000 | loss: 0.250\n",
      "| steps 0078000 | Validation Accuracy: 0.386\n",
      "| steps 0078100 | loss: 0.406\n",
      "| steps 0078100 | Validation Accuracy: 0.421\n",
      "| steps 0078200 | loss: 0.219\n",
      "| steps 0078200 | Validation Accuracy: 0.491\n",
      "| steps 0078300 | loss: 0.312\n",
      "| steps 0078300 | Validation Accuracy: 0.316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| steps 0078400 | loss: 0.375\n",
      "| steps 0078400 | Validation Accuracy: 0.456\n",
      "| steps 0078500 | loss: 0.156\n",
      "| steps 0078500 | Validation Accuracy: 0.351\n",
      "| steps 0078600 | loss: 0.250\n",
      "| steps 0078600 | Validation Accuracy: 0.386\n",
      "| steps 0078700 | loss: 0.219\n",
      "| steps 0078700 | Validation Accuracy: 0.421\n",
      "| steps 0078800 | loss: 0.344\n",
      "| steps 0078800 | Validation Accuracy: 0.439\n",
      "| steps 0078900 | loss: 0.250\n",
      "| steps 0078900 | Validation Accuracy: 0.368\n",
      "| steps 0079000 | loss: 0.469\n",
      "| steps 0079000 | Validation Accuracy: 0.439\n",
      "| steps 0079100 | loss: 0.281\n",
      "| steps 0079100 | Validation Accuracy: 0.368\n",
      "| steps 0079200 | loss: 0.250\n",
      "| steps 0079200 | Validation Accuracy: 0.368\n",
      "| steps 0079300 | loss: 0.406\n",
      "| steps 0079300 | Validation Accuracy: 0.439\n",
      "| steps 0079400 | loss: 0.406\n",
      "| steps 0079400 | Validation Accuracy: 0.404\n",
      "| steps 0079500 | loss: 0.469\n",
      "| steps 0079500 | Validation Accuracy: 0.404\n",
      "| steps 0079600 | loss: 0.406\n",
      "| steps 0079600 | Validation Accuracy: 0.386\n",
      "| steps 0079700 | loss: 0.188\n",
      "| steps 0079700 | Validation Accuracy: 0.421\n",
      "| steps 0079800 | loss: 0.406\n",
      "| steps 0079800 | Validation Accuracy: 0.439\n",
      "| steps 0079900 | loss: 0.219\n",
      "| steps 0079900 | Validation Accuracy: 0.368\n",
      "| steps 0080000 | loss: 0.344\n",
      "| steps 0080000 | Validation Accuracy: 0.474\n",
      "| steps 0080100 | loss: 0.281\n",
      "| steps 0080100 | Validation Accuracy: 0.333\n",
      "| steps 0080200 | loss: 0.312\n",
      "| steps 0080200 | Validation Accuracy: 0.368\n",
      "| steps 0080300 | loss: 0.406\n",
      "| steps 0080300 | Validation Accuracy: 0.439\n",
      "| steps 0080400 | loss: 0.281\n",
      "| steps 0080400 | Validation Accuracy: 0.368\n",
      "| steps 0080500 | loss: 0.312\n",
      "| steps 0080500 | Validation Accuracy: 0.439\n",
      "| steps 0080600 | loss: 0.375\n",
      "| steps 0080600 | Validation Accuracy: 0.439\n",
      "| steps 0080700 | loss: 0.344\n",
      "| steps 0080700 | Validation Accuracy: 0.368\n",
      "| steps 0080800 | loss: 0.281\n",
      "| steps 0080800 | Validation Accuracy: 0.386\n",
      "| steps 0080900 | loss: 0.281\n",
      "| steps 0080900 | Validation Accuracy: 0.421\n",
      "| steps 0081000 | loss: 0.250\n",
      "| steps 0081000 | Validation Accuracy: 0.439\n",
      "| steps 0081100 | loss: 0.406\n",
      "| steps 0081100 | Validation Accuracy: 0.368\n",
      "| steps 0081200 | loss: 0.406\n",
      "| steps 0081200 | Validation Accuracy: 0.474\n",
      "| steps 0081300 | loss: 0.281\n",
      "| steps 0081300 | Validation Accuracy: 0.333\n",
      "| steps 0081400 | loss: 0.250\n",
      "| steps 0081400 | Validation Accuracy: 0.386\n",
      "| steps 0081500 | loss: 0.469\n",
      "| steps 0081500 | Validation Accuracy: 0.421\n",
      "| steps 0081600 | loss: 0.219\n",
      "| steps 0081600 | Validation Accuracy: 0.351\n",
      "| steps 0081700 | loss: 0.344\n",
      "| steps 0081700 | Validation Accuracy: 0.456\n",
      "| steps 0081800 | loss: 0.250\n",
      "| steps 0081800 | Validation Accuracy: 0.386\n",
      "| steps 0081900 | loss: 0.188\n",
      "| steps 0081900 | Validation Accuracy: 0.421\n",
      "| steps 0082000 | loss: 0.375\n",
      "| steps 0082000 | Validation Accuracy: 0.351\n",
      "| steps 0082100 | loss: 0.219\n",
      "| steps 0082100 | Validation Accuracy: 0.456\n",
      "| steps 0082200 | loss: 0.281\n",
      "| steps 0082200 | Validation Accuracy: 0.439\n",
      "| steps 0082300 | loss: 0.281\n",
      "| steps 0082300 | Validation Accuracy: 0.368\n",
      "| steps 0082400 | loss: 0.344\n",
      "| steps 0082400 | Validation Accuracy: 0.386\n",
      "| steps 0082500 | loss: 0.219\n",
      "| steps 0082500 | Validation Accuracy: 0.421\n",
      "| steps 0082600 | loss: 0.219\n",
      "| steps 0082600 | Validation Accuracy: 0.368\n",
      "| steps 0082700 | loss: 0.344\n",
      "| steps 0082700 | Validation Accuracy: 0.439\n",
      "| steps 0082800 | loss: 0.250\n",
      "| steps 0082800 | Validation Accuracy: 0.351\n",
      "| steps 0082900 | loss: 0.250\n",
      "| steps 0082900 | Validation Accuracy: 0.456\n",
      "| steps 0083000 | loss: 0.344\n",
      "| steps 0083000 | Validation Accuracy: 0.439\n",
      "| steps 0083100 | loss: 0.312\n",
      "| steps 0083100 | Validation Accuracy: 0.368\n",
      "| steps 0083200 | loss: 0.375\n",
      "| steps 0083200 | Validation Accuracy: 0.456\n",
      "| steps 0083300 | loss: 0.250\n",
      "| steps 0083300 | Validation Accuracy: 0.351\n",
      "| steps 0083400 | loss: 0.344\n",
      "| steps 0083400 | Validation Accuracy: 0.474\n",
      "| steps 0083500 | loss: 0.375\n",
      "| steps 0083500 | Validation Accuracy: 0.333\n",
      "| steps 0083600 | loss: 0.406\n",
      "| steps 0083600 | Validation Accuracy: 0.404\n",
      "| steps 0083700 | loss: 0.156\n",
      "| steps 0083700 | Validation Accuracy: 0.404\n",
      "| steps 0083800 | loss: 0.406\n",
      "| steps 0083800 | Validation Accuracy: 0.491\n",
      "| steps 0083900 | loss: 0.219\n",
      "| steps 0083900 | Validation Accuracy: 0.316\n",
      "| steps 0084000 | loss: 0.438\n",
      "| steps 0084000 | Validation Accuracy: 0.456\n",
      "| steps 0084100 | loss: 0.281\n",
      "| steps 0084100 | Validation Accuracy: 0.351\n",
      "| steps 0084200 | loss: 0.469\n",
      "| steps 0084200 | Validation Accuracy: 0.421\n",
      "| steps 0084300 | loss: 0.250\n",
      "| steps 0084300 | Validation Accuracy: 0.386\n",
      "| steps 0084400 | loss: 0.250\n",
      "| steps 0084400 | Validation Accuracy: 0.491\n",
      "| steps 0084500 | loss: 0.281\n",
      "| steps 0084500 | Validation Accuracy: 0.316\n",
      "| steps 0084600 | loss: 0.438\n",
      "| steps 0084600 | Validation Accuracy: 0.439\n",
      "| steps 0084700 | loss: 0.406\n",
      "| steps 0084700 | Validation Accuracy: 0.368\n",
      "| steps 0084800 | loss: 0.406\n",
      "| steps 0084800 | Validation Accuracy: 0.368\n",
      "| steps 0084900 | loss: 0.281\n",
      "| steps 0084900 | Validation Accuracy: 0.439\n",
      "| steps 0085000 | loss: 0.344\n",
      "| steps 0085000 | Validation Accuracy: 0.439\n",
      "| steps 0085100 | loss: 0.531\n",
      "| steps 0085100 | Validation Accuracy: 0.368\n",
      "| steps 0085200 | loss: 0.375\n",
      "| steps 0085200 | Validation Accuracy: 0.368\n",
      "| steps 0085300 | loss: 0.344\n",
      "| steps 0085300 | Validation Accuracy: 0.439\n",
      "| steps 0085400 | loss: 0.312\n",
      "| steps 0085400 | Validation Accuracy: 0.439\n",
      "| steps 0085500 | loss: 0.188\n",
      "| steps 0085500 | Validation Accuracy: 0.368\n",
      "| steps 0085600 | loss: 0.125\n",
      "| steps 0085600 | Validation Accuracy: 0.404\n",
      "| steps 0085700 | loss: 0.406\n",
      "| steps 0085700 | Validation Accuracy: 0.404\n",
      "| steps 0085800 | loss: 0.344\n",
      "| steps 0085800 | Validation Accuracy: 0.386\n",
      "| steps 0085900 | loss: 0.406\n",
      "| steps 0085900 | Validation Accuracy: 0.421\n",
      "| steps 0086000 | loss: 0.156\n",
      "| steps 0086000 | Validation Accuracy: 0.333\n",
      "| steps 0086100 | loss: 0.344\n",
      "| steps 0086100 | Validation Accuracy: 0.474\n",
      "| steps 0086200 | loss: 0.438\n",
      "| steps 0086200 | Validation Accuracy: 0.491\n",
      "| steps 0086300 | loss: 0.312\n",
      "| steps 0086300 | Validation Accuracy: 0.316\n",
      "| steps 0086400 | loss: 0.250\n",
      "| steps 0086400 | Validation Accuracy: 0.404\n",
      "| steps 0086500 | loss: 0.188\n",
      "| steps 0086500 | Validation Accuracy: 0.404\n",
      "| steps 0086600 | loss: 0.344\n",
      "| steps 0086600 | Validation Accuracy: 0.421\n",
      "| steps 0086700 | loss: 0.125\n",
      "| steps 0086700 | Validation Accuracy: 0.386\n",
      "| steps 0086800 | loss: 0.281\n",
      "| steps 0086800 | Validation Accuracy: 0.351\n",
      "| steps 0086900 | loss: 0.250\n",
      "| steps 0086900 | Validation Accuracy: 0.456\n",
      "| steps 0087000 | loss: 0.344\n",
      "| steps 0087000 | Validation Accuracy: 0.316\n",
      "| steps 0087100 | loss: 0.250\n",
      "| steps 0087100 | Validation Accuracy: 0.491\n",
      "| steps 0087200 | loss: 0.344\n",
      "| steps 0087200 | Validation Accuracy: 0.474\n",
      "| steps 0087300 | loss: 0.344\n",
      "| steps 0087300 | Validation Accuracy: 0.333\n",
      "| steps 0087400 | loss: 0.188\n",
      "| steps 0087400 | Validation Accuracy: 0.404\n",
      "| steps 0087500 | loss: 0.375\n",
      "| steps 0087500 | Validation Accuracy: 0.404\n",
      "| steps 0087600 | loss: 0.156\n",
      "| steps 0087600 | Validation Accuracy: 0.298\n",
      "| steps 0087700 | loss: 0.281\n",
      "| steps 0087700 | Validation Accuracy: 0.509\n",
      "| steps 0087800 | loss: 0.344\n",
      "| steps 0087800 | Validation Accuracy: 0.386\n",
      "| steps 0087900 | loss: 0.281\n",
      "| steps 0087900 | Validation Accuracy: 0.421\n",
      "| steps 0088000 | loss: 0.344\n",
      "| steps 0088000 | Validation Accuracy: 0.386\n",
      "| steps 0088100 | loss: 0.250\n",
      "| steps 0088100 | Validation Accuracy: 0.421\n",
      "| steps 0088200 | loss: 0.312\n",
      "| steps 0088200 | Validation Accuracy: 0.474\n",
      "| steps 0088300 | loss: 0.312\n",
      "| steps 0088300 | Validation Accuracy: 0.333\n",
      "| steps 0088400 | loss: 0.375\n",
      "| steps 0088400 | Validation Accuracy: 0.351\n",
      "| steps 0088500 | loss: 0.406\n",
      "| steps 0088500 | Validation Accuracy: 0.456\n",
      "| steps 0088600 | loss: 0.312\n",
      "| steps 0088600 | Validation Accuracy: 0.386\n",
      "| steps 0088700 | loss: 0.281\n",
      "| steps 0088700 | Validation Accuracy: 0.421\n",
      "| steps 0088800 | loss: 0.406\n",
      "| steps 0088800 | Validation Accuracy: 0.456\n",
      "| steps 0088900 | loss: 0.375\n",
      "| steps 0088900 | Validation Accuracy: 0.351\n",
      "| steps 0089000 | loss: 0.375\n",
      "| steps 0089000 | Validation Accuracy: 0.421\n",
      "| steps 0089100 | loss: 0.125\n",
      "| steps 0089100 | Validation Accuracy: 0.386\n",
      "| steps 0089200 | loss: 0.312\n",
      "| steps 0089200 | Validation Accuracy: 0.404\n",
      "| steps 0089300 | loss: 0.438\n",
      "| steps 0089300 | Validation Accuracy: 0.404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| steps 0089400 | loss: 0.156\n",
      "| steps 0089400 | Validation Accuracy: 0.526\n",
      "| steps 0089500 | loss: 0.375\n",
      "| steps 0089500 | Validation Accuracy: 0.281\n",
      "| steps 0089600 | loss: 0.438\n",
      "| steps 0089600 | Validation Accuracy: 0.386\n",
      "| steps 0089700 | loss: 0.312\n",
      "| steps 0089700 | Validation Accuracy: 0.421\n",
      "| steps 0089800 | loss: 0.281\n",
      "| steps 0089800 | Validation Accuracy: 0.333\n",
      "| steps 0089900 | loss: 0.406\n",
      "| steps 0089900 | Validation Accuracy: 0.474\n",
      "| steps 0090000 | loss: 0.344\n",
      "| steps 0090000 | Validation Accuracy: 0.368\n",
      "| steps 0090100 | loss: 0.312\n",
      "| steps 0090100 | Validation Accuracy: 0.439\n",
      "| steps 0090200 | loss: 0.375\n",
      "| steps 0090200 | Validation Accuracy: 0.456\n",
      "| steps 0090300 | loss: 0.375\n",
      "| steps 0090300 | Validation Accuracy: 0.351\n",
      "| steps 0090400 | loss: 0.250\n",
      "| steps 0090400 | Validation Accuracy: 0.386\n",
      "| steps 0090500 | loss: 0.344\n",
      "| steps 0090500 | Validation Accuracy: 0.421\n",
      "| steps 0090600 | loss: 0.281\n",
      "| steps 0090600 | Validation Accuracy: 0.404\n",
      "| steps 0090700 | loss: 0.312\n",
      "| steps 0090700 | Validation Accuracy: 0.404\n",
      "| steps 0090800 | loss: 0.375\n",
      "| steps 0090800 | Validation Accuracy: 0.404\n",
      "| steps 0090900 | loss: 0.281\n",
      "| steps 0090900 | Validation Accuracy: 0.404\n",
      "| steps 0091000 | loss: 0.438\n",
      "| steps 0091000 | Validation Accuracy: 0.386\n",
      "| steps 0091100 | loss: 0.312\n",
      "| steps 0091100 | Validation Accuracy: 0.421\n",
      "| steps 0091200 | loss: 0.344\n",
      "| steps 0091200 | Validation Accuracy: 0.439\n",
      "| steps 0091300 | loss: 0.469\n",
      "| steps 0091300 | Validation Accuracy: 0.368\n",
      "| steps 0091400 | loss: 0.281\n",
      "| steps 0091400 | Validation Accuracy: 0.439\n",
      "| steps 0091500 | loss: 0.250\n",
      "| steps 0091500 | Validation Accuracy: 0.368\n",
      "| steps 0091600 | loss: 0.531\n",
      "| steps 0091600 | Validation Accuracy: 0.474\n",
      "| steps 0091700 | loss: 0.281\n",
      "| steps 0091700 | Validation Accuracy: 0.333\n",
      "| steps 0091800 | loss: 0.344\n",
      "| steps 0091800 | Validation Accuracy: 0.351\n",
      "| steps 0091900 | loss: 0.281\n",
      "| steps 0091900 | Validation Accuracy: 0.456\n",
      "| steps 0092000 | loss: 0.312\n",
      "| steps 0092000 | Validation Accuracy: 0.368\n",
      "| steps 0092100 | loss: 0.344\n",
      "| steps 0092100 | Validation Accuracy: 0.439\n",
      "| steps 0092200 | loss: 0.344\n",
      "| steps 0092200 | Validation Accuracy: 0.351\n",
      "| steps 0092300 | loss: 0.344\n",
      "| steps 0092300 | Validation Accuracy: 0.456\n",
      "| steps 0092400 | loss: 0.344\n",
      "| steps 0092400 | Validation Accuracy: 0.386\n",
      "| steps 0092500 | loss: 0.281\n",
      "| steps 0092500 | Validation Accuracy: 0.421\n",
      "| steps 0092600 | loss: 0.250\n",
      "| steps 0092600 | Validation Accuracy: 0.316\n",
      "| steps 0092700 | loss: 0.281\n",
      "| steps 0092700 | Validation Accuracy: 0.491\n",
      "| steps 0092800 | loss: 0.438\n",
      "| steps 0092800 | Validation Accuracy: 0.368\n",
      "| steps 0092900 | loss: 0.312\n",
      "| steps 0092900 | Validation Accuracy: 0.439\n",
      "| steps 0093000 | loss: 0.500\n",
      "| steps 0093000 | Validation Accuracy: 0.456\n",
      "| steps 0093100 | loss: 0.281\n",
      "| steps 0093100 | Validation Accuracy: 0.351\n",
      "| steps 0093200 | loss: 0.281\n",
      "| steps 0093200 | Validation Accuracy: 0.386\n",
      "| steps 0093300 | loss: 0.312\n",
      "| steps 0093300 | Validation Accuracy: 0.421\n",
      "| steps 0093400 | loss: 0.500\n",
      "| steps 0093400 | Validation Accuracy: 0.368\n",
      "| steps 0093500 | loss: 0.344\n",
      "| steps 0093500 | Validation Accuracy: 0.439\n",
      "| steps 0093600 | loss: 0.406\n",
      "| steps 0093600 | Validation Accuracy: 0.316\n",
      "| steps 0093700 | loss: 0.250\n",
      "| steps 0093700 | Validation Accuracy: 0.491\n",
      "| steps 0093800 | loss: 0.312\n",
      "| steps 0093800 | Validation Accuracy: 0.456\n",
      "| steps 0093900 | loss: 0.281\n",
      "| steps 0093900 | Validation Accuracy: 0.351\n",
      "| steps 0094000 | loss: 0.156\n",
      "| steps 0094000 | Validation Accuracy: 0.316\n",
      "| steps 0094100 | loss: 0.438\n",
      "| steps 0094100 | Validation Accuracy: 0.491\n",
      "| steps 0094200 | loss: 0.438\n",
      "| steps 0094200 | Validation Accuracy: 0.456\n",
      "| steps 0094300 | loss: 0.250\n",
      "| steps 0094300 | Validation Accuracy: 0.351\n",
      "| steps 0094400 | loss: 0.312\n",
      "| steps 0094400 | Validation Accuracy: 0.386\n",
      "| steps 0094500 | loss: 0.406\n",
      "| steps 0094500 | Validation Accuracy: 0.421\n",
      "| steps 0094600 | loss: 0.188\n",
      "| steps 0094600 | Validation Accuracy: 0.404\n",
      "| steps 0094700 | loss: 0.312\n",
      "| steps 0094700 | Validation Accuracy: 0.404\n",
      "| steps 0094800 | loss: 0.250\n",
      "| steps 0094800 | Validation Accuracy: 0.386\n",
      "| steps 0094900 | loss: 0.219\n",
      "| steps 0094900 | Validation Accuracy: 0.421\n",
      "| steps 0095000 | loss: 0.438\n",
      "| steps 0095000 | Validation Accuracy: 0.509\n",
      "| steps 0095100 | loss: 0.219\n",
      "| steps 0095100 | Validation Accuracy: 0.298\n",
      "| steps 0095200 | loss: 0.344\n",
      "| steps 0095200 | Validation Accuracy: 0.368\n",
      "| steps 0095300 | loss: 0.469\n",
      "| steps 0095300 | Validation Accuracy: 0.439\n",
      "| steps 0095400 | loss: 0.250\n",
      "| steps 0095400 | Validation Accuracy: 0.439\n",
      "| steps 0095500 | loss: 0.312\n",
      "| steps 0095500 | Validation Accuracy: 0.368\n",
      "| steps 0095600 | loss: 0.469\n",
      "| steps 0095600 | Validation Accuracy: 0.491\n",
      "| steps 0095700 | loss: 0.406\n",
      "| steps 0095700 | Validation Accuracy: 0.316\n",
      "| steps 0095800 | loss: 0.375\n",
      "| steps 0095800 | Validation Accuracy: 0.386\n",
      "| steps 0095900 | loss: 0.500\n",
      "| steps 0095900 | Validation Accuracy: 0.421\n",
      "| steps 0096000 | loss: 0.375\n",
      "| steps 0096000 | Validation Accuracy: 0.298\n",
      "| steps 0096100 | loss: 0.312\n",
      "| steps 0096100 | Validation Accuracy: 0.509\n",
      "| steps 0096200 | loss: 0.219\n",
      "| steps 0096200 | Validation Accuracy: 0.404\n",
      "| steps 0096300 | loss: 0.219\n",
      "| steps 0096300 | Validation Accuracy: 0.404\n",
      "| steps 0096400 | loss: 0.375\n",
      "| steps 0096400 | Validation Accuracy: 0.404\n",
      "| steps 0096500 | loss: 0.344\n",
      "| steps 0096500 | Validation Accuracy: 0.404\n",
      "| steps 0096600 | loss: 0.375\n",
      "| steps 0096600 | Validation Accuracy: 0.439\n",
      "| steps 0096700 | loss: 0.375\n",
      "| steps 0096700 | Validation Accuracy: 0.368\n",
      "| steps 0096800 | loss: 0.156\n",
      "| steps 0096800 | Validation Accuracy: 0.474\n",
      "| steps 0096900 | loss: 0.281\n",
      "| steps 0096900 | Validation Accuracy: 0.333\n",
      "| steps 0097000 | loss: 0.344\n",
      "| steps 0097000 | Validation Accuracy: 0.368\n",
      "| steps 0097100 | loss: 0.312\n",
      "| steps 0097100 | Validation Accuracy: 0.439\n",
      "| steps 0097200 | loss: 0.281\n",
      "| steps 0097200 | Validation Accuracy: 0.509\n",
      "| steps 0097300 | loss: 0.281\n",
      "| steps 0097300 | Validation Accuracy: 0.298\n",
      "| steps 0097400 | loss: 0.219\n",
      "| steps 0097400 | Validation Accuracy: 0.421\n",
      "| steps 0097500 | loss: 0.250\n",
      "| steps 0097500 | Validation Accuracy: 0.386\n",
      "| steps 0097600 | loss: 0.250\n",
      "| steps 0097600 | Validation Accuracy: 0.386\n",
      "| steps 0097700 | loss: 0.344\n",
      "| steps 0097700 | Validation Accuracy: 0.421\n",
      "| steps 0097800 | loss: 0.406\n",
      "| steps 0097800 | Validation Accuracy: 0.386\n",
      "| steps 0097900 | loss: 0.188\n",
      "| steps 0097900 | Validation Accuracy: 0.421\n",
      "| steps 0098000 | loss: 0.344\n",
      "| steps 0098000 | Validation Accuracy: 0.386\n",
      "| steps 0098100 | loss: 0.375\n",
      "| steps 0098100 | Validation Accuracy: 0.421\n",
      "| steps 0098200 | loss: 0.250\n",
      "| steps 0098200 | Validation Accuracy: 0.386\n",
      "| steps 0098300 | loss: 0.281\n",
      "| steps 0098300 | Validation Accuracy: 0.421\n",
      "| steps 0098400 | loss: 0.438\n",
      "| steps 0098400 | Validation Accuracy: 0.439\n",
      "| steps 0098500 | loss: 0.312\n",
      "| steps 0098500 | Validation Accuracy: 0.368\n",
      "| steps 0098600 | loss: 0.344\n",
      "| steps 0098600 | Validation Accuracy: 0.456\n",
      "| steps 0098700 | loss: 0.250\n",
      "| steps 0098700 | Validation Accuracy: 0.351\n",
      "| steps 0098800 | loss: 0.281\n",
      "| steps 0098800 | Validation Accuracy: 0.421\n",
      "| steps 0098900 | loss: 0.312\n",
      "| steps 0098900 | Validation Accuracy: 0.386\n",
      "| steps 0099000 | loss: 0.312\n",
      "| steps 0099000 | Validation Accuracy: 0.386\n",
      "| steps 0099100 | loss: 0.375\n",
      "| steps 0099100 | Validation Accuracy: 0.421\n",
      "| steps 0099200 | loss: 0.062\n",
      "| steps 0099200 | Validation Accuracy: 0.421\n",
      "| steps 0099300 | loss: 0.188\n",
      "| steps 0099300 | Validation Accuracy: 0.386\n",
      "| steps 0099400 | loss: 0.344\n",
      "| steps 0099400 | Validation Accuracy: 0.351\n",
      "| steps 0099500 | loss: 0.250\n",
      "| steps 0099500 | Validation Accuracy: 0.456\n",
      "| steps 0099600 | loss: 0.344\n",
      "| steps 0099600 | Validation Accuracy: 0.404\n",
      "| steps 0099700 | loss: 0.344\n",
      "| steps 0099700 | Validation Accuracy: 0.404\n",
      "| steps 0099800 | loss: 0.375\n",
      "| steps 0099800 | Validation Accuracy: 0.421\n",
      "| steps 0099900 | loss: 0.219\n",
      "| steps 0099900 | Validation Accuracy: 0.386\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Loading data reader at Practice(2)\n",
    "data_reader = reader()\n",
    "\n",
    "# Loading DNN graph at Practice(3)\n",
    "model = dnn()\n",
    "\n",
    "# Define Session for running graph\n",
    "# and initialize model's parameters\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_steps = 100000\n",
    "for i in range(max_steps):\n",
    "  # For each iteration, first we get batch x&y data\n",
    "  x_train, y_train, id_train = data_reader.next_batch(batch_size, split=\"train\")\n",
    "\n",
    "  # Next, construct feed for model's placeholder\n",
    "  # feed is dictionary whose key is placeholder, and value is feeded value(numpy array)\n",
    "  feed = {model.x: x_train, model.y: y_train}\n",
    "\n",
    "  # Go training via running train_op with feeded data!\n",
    "  # We run simultaneously train_op(backprop) and loss value\n",
    "  _, loss = sess.run([model.train_op, model.loss], feed_dict=feed)\n",
    "\n",
    "  # print loss stat every 100 iterations\n",
    "  if i%100 == 0:\n",
    "    print \"| steps %07d | loss: %.3lf\" % (i, loss)\n",
    "\n",
    "\n",
    "  # running validation process every 100 iterations\n",
    "  if i%100 == 0:\n",
    "    x_val, y_val, id_val = data_reader.next_batch(57, split=\"val\")\n",
    "    feed_val = {model.x: x_val, model.y: y_val}\n",
    "\n",
    "    validation_acc = sess.run(model.acc, feed_dict=feed_val)\n",
    "    print \"| steps %07d | Validation Accuracy: %.3lf\" % (i, validation_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
